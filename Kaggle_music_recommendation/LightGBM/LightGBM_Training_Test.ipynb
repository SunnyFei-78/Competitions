{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM模型训练\n",
    "1. 选择验证集上AUC分数最高的参数做训练\n",
    "2. 对训练集70%-100%位置的数据做训练，得到模型A\n",
    "3. 对训练集50%-70%位置的数据做训练，得到模型B\n",
    "4. 对训练集30%-50%位置的数据做训练，得到模型C\n",
    "5. 对训练集10%-30%位置的数据做训练，得到模型D\n",
    "6. 对模型ABCD做两种方式的融合：\n",
    "\n",
    "   一：做平均，得到模型E\n",
    "   \n",
    "   二：加权系数分别是0.6：0.2：0.1：0.1， 得到模型F\n",
    "   \n",
    "7. 分别用以下模型对测试集做预测，结果提交Kaggle，得到public分数如下：\n",
    "\n",
    "   模型A：0.70386 (第37名)\n",
    "   \n",
    "   模型E：0.70290 (第42名)\n",
    "   \n",
    "   模型F：0.70987 (第22名)\n",
    "   \n",
    "以上结果可以发现，训练集的后30%占比越高，AUC的分值越高；同时其他剩下的训练数据有一定的弥补作用。\n",
    "所以最终选择模型F，和神经网络模型做融合。\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/package')\n",
    "\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_all = pd.read_csv('./music_test/train_nn.csv')\n",
    "test_all = pd.read_csv('./music_test/test_nn.csv')\n",
    "members = pd.read_csv('./music_test/members_nn.csv')\n",
    "songs = pd.read_csv('./music_test/songs_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7377418, 48, 2556790, 48, 34403, 143, 419839, 102)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.shape + test_all.shape + members.shape + songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 取训练集中最后30%的数据，进行第一次模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_all[math.ceil(train_all.shape[0]*0.7):]\n",
    "test = test_all[:]\n",
    "\n",
    "train_y = train['target']\n",
    "train.drop(['target'], inplace=True, axis=1)\n",
    "\n",
    "test_y = test['id']\n",
    "test.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "# 新增几个时间特征\n",
    "train['time_spent'] = train['timestamp'] - train['registration_init_time']\n",
    "test['time_spent'] = test['timestamp'] - test['registration_init_time']\n",
    "\n",
    "train['time_left'] = train['expiration_date'] - train['timestamp']\n",
    "test['time_left'] = test['expiration_date'] - test['timestamp']\n",
    "\n",
    "train['msno_upper_time'] = train['msno_timestamp_mean'] + train['msno_timestamp_std']\n",
    "test['msno_upper_time'] = test['msno_timestamp_mean'] + test['msno_timestamp_std']\n",
    "\n",
    "train['msno_lower_time'] = train['msno_timestamp_mean'] - train['msno_timestamp_std']\n",
    "test['msno_lower_time'] = test['msno_timestamp_mean'] - test['msno_timestamp_std']\n",
    "\n",
    "train['song_upper_time'] = train['song_timestamp_mean'] + train['song_timestamp_std']\n",
    "test['song_upper_time'] = test['song_timestamp_mean'] + test['song_timestamp_std']\n",
    "\n",
    "train['song_lower_time'] = train['song_timestamp_mean'] - train['song_timestamp_std']\n",
    "test['song_lower_time'] = test['song_timestamp_mean'] - test['song_timestamp_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 取训练集中50%-70%位置的数据，进行第二次模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train = train_all[math.ceil(train_all.shape[0]*0.5):math.ceil(train_all.shape[0]*0.7)]\n",
    "test = test_all[:]\n",
    "\n",
    "train_y = train['target']\n",
    "train.drop(['target'], inplace=True, axis=1)\n",
    "\n",
    "test_id = test['id']\n",
    "test.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "# 新增几个时间特征\n",
    "train['time_spent'] = train['timestamp'] - train['registration_init_time']\n",
    "test['time_spent'] = test['timestamp'] - test['registration_init_time']\n",
    "\n",
    "train['time_left'] = train['expiration_date'] - train['timestamp']\n",
    "test['time_left'] = test['expiration_date'] - test['timestamp']\n",
    "\n",
    "train['msno_upper_time'] = train['msno_timestamp_mean'] + train['msno_timestamp_std']\n",
    "test['msno_upper_time'] = test['msno_timestamp_mean'] + test['msno_timestamp_std']\n",
    "\n",
    "train['msno_lower_time'] = train['msno_timestamp_mean'] - train['msno_timestamp_std']\n",
    "test['msno_lower_time'] = test['msno_timestamp_mean'] - test['msno_timestamp_std']\n",
    "\n",
    "train['song_upper_time'] = train['song_timestamp_mean'] + train['song_timestamp_std']\n",
    "test['song_upper_time'] = test['song_timestamp_mean'] + test['song_timestamp_std']\n",
    "\n",
    "train['song_lower_time'] = train['song_timestamp_mean'] - train['song_timestamp_std']\n",
    "test['song_lower_time'] = test['song_timestamp_mean'] - test['song_timestamp_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1475484, 296, 2556790, 296)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape + test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 取训练集中30%-50%位置的数据，进行第三次模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train = train_all[math.ceil(train_all.shape[0]*0.3):math.ceil(train_all.shape[0]*0.5)]\n",
    "test = test_all[:]\n",
    "\n",
    "train_y = train['target']\n",
    "train.drop(['target'], inplace=True, axis=1)\n",
    "\n",
    "test_id = test['id']\n",
    "test.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "# 新增几个时间特征\n",
    "train['time_spent'] = train['timestamp'] - train['registration_init_time']\n",
    "test['time_spent'] = test['timestamp'] - test['registration_init_time']\n",
    "\n",
    "train['time_left'] = train['expiration_date'] - train['timestamp']\n",
    "test['time_left'] = test['expiration_date'] - test['timestamp']\n",
    "\n",
    "train['msno_upper_time'] = train['msno_timestamp_mean'] + train['msno_timestamp_std']\n",
    "test['msno_upper_time'] = test['msno_timestamp_mean'] + test['msno_timestamp_std']\n",
    "\n",
    "train['msno_lower_time'] = train['msno_timestamp_mean'] - train['msno_timestamp_std']\n",
    "test['msno_lower_time'] = test['msno_timestamp_mean'] - test['msno_timestamp_std']\n",
    "\n",
    "train['song_upper_time'] = train['song_timestamp_mean'] + train['song_timestamp_std']\n",
    "test['song_upper_time'] = test['song_timestamp_mean'] + test['song_timestamp_std']\n",
    "\n",
    "train['song_lower_time'] = train['song_timestamp_mean'] - train['song_timestamp_std']\n",
    "test['song_lower_time'] = test['song_timestamp_mean'] - test['song_timestamp_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 取训练集中10%-30%位置的数据，进行第四次模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train = train_all[math.ceil(train_all.shape[0]*0.1):math.ceil(train_all.shape[0]*0.3)]\n",
    "test = test_all[:]\n",
    "\n",
    "train_y = train['target']\n",
    "train.drop(['target'], inplace=True, axis=1)\n",
    "\n",
    "test_id = test['id']\n",
    "test.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "# 新增几个时间特征\n",
    "train['time_spent'] = train['timestamp'] - train['registration_init_time']\n",
    "test['time_spent'] = test['timestamp'] - test['registration_init_time']\n",
    "\n",
    "train['time_left'] = train['expiration_date'] - train['timestamp']\n",
    "test['time_left'] = test['expiration_date'] - test['timestamp']\n",
    "\n",
    "train['msno_upper_time'] = train['msno_timestamp_mean'] + train['msno_timestamp_std']\n",
    "test['msno_upper_time'] = test['msno_timestamp_mean'] + test['msno_timestamp_std']\n",
    "\n",
    "train['msno_lower_time'] = train['msno_timestamp_mean'] - train['msno_timestamp_std']\n",
    "test['msno_lower_time'] = test['msno_timestamp_mean'] - test['msno_timestamp_std']\n",
    "\n",
    "train['song_upper_time'] = train['song_timestamp_mean'] + train['song_timestamp_std']\n",
    "test['song_upper_time'] = test['song_timestamp_mean'] + test['song_timestamp_std']\n",
    "\n",
    "train['song_lower_time'] = train['song_timestamp_mean'] - train['song_timestamp_std']\n",
    "test['song_lower_time'] = test['song_timestamp_mean'] - test['song_timestamp_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## feature selection\n",
    "# feat_importance = pd.read_csv('./music_val/feat_importance_0316_01.csv')\n",
    "# feature_name = feat_importance['name'].values\n",
    "# feature_importance = feat_importance['importance'].values\n",
    "\n",
    "# col_to_drop_by_importance = feature_name[feature_importance<85]\n",
    "# train.drop(col_to_drop_by_importance, axis=1, inplace=True)\n",
    "# test.drop(col_to_drop_by_importance, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model training\n",
    "train_data = lgbm.Dataset(train, label=train_y, free_raw_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 利用lightGBM模型预测测试集，产生提交结果\n",
    "验证集上AUC最高分数是0.76442"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1）max_depth=10，num_leaves=220，min_data_in_leaf=500，l1=6， l2=2000，5000轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameters:\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'learning_rate': 0.1, 'num_leaves': 220, 'max_depth': 10, 'min_data_in_leaf': 500, 'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'lambda_l1': 6, 'lambda_l2': 2000, 'min_gain_to_split': 0, 'min_sum_hessian_in_leaf': 0.1, 'num_threads': 16, 'verbose': 0, 'is_training_metric': 'True'}\n",
      "[100]\ttraining's binary_logloss: 0.489591\ttraining's auc: 0.834941\n",
      "[200]\ttraining's binary_logloss: 0.46442\ttraining's auc: 0.854836\n",
      "[300]\ttraining's binary_logloss: 0.447034\ttraining's auc: 0.867681\n",
      "[400]\ttraining's binary_logloss: 0.434268\ttraining's auc: 0.876593\n",
      "[500]\ttraining's binary_logloss: 0.42397\ttraining's auc: 0.883552\n",
      "[600]\ttraining's binary_logloss: 0.414546\ttraining's auc: 0.889725\n",
      "[700]\ttraining's binary_logloss: 0.406696\ttraining's auc: 0.894732\n",
      "[800]\ttraining's binary_logloss: 0.399315\ttraining's auc: 0.899355\n",
      "[900]\ttraining's binary_logloss: 0.39273\ttraining's auc: 0.903395\n",
      "[1000]\ttraining's binary_logloss: 0.386694\ttraining's auc: 0.907045\n",
      "[1100]\ttraining's binary_logloss: 0.380889\ttraining's auc: 0.910496\n",
      "[1200]\ttraining's binary_logloss: 0.375235\ttraining's auc: 0.913814\n",
      "[1300]\ttraining's binary_logloss: 0.369662\ttraining's auc: 0.917051\n",
      "[1400]\ttraining's binary_logloss: 0.364632\ttraining's auc: 0.919923\n",
      "[1500]\ttraining's binary_logloss: 0.359628\ttraining's auc: 0.922758\n",
      "[1600]\ttraining's binary_logloss: 0.354884\ttraining's auc: 0.925409\n",
      "[1700]\ttraining's binary_logloss: 0.35022\ttraining's auc: 0.92797\n",
      "[1800]\ttraining's binary_logloss: 0.345879\ttraining's auc: 0.930314\n",
      "[1900]\ttraining's binary_logloss: 0.341687\ttraining's auc: 0.932567\n",
      "[2000]\ttraining's binary_logloss: 0.337445\ttraining's auc: 0.934818\n",
      "[2100]\ttraining's binary_logloss: 0.333341\ttraining's auc: 0.936961\n",
      "[2200]\ttraining's binary_logloss: 0.329326\ttraining's auc: 0.939036\n",
      "[2300]\ttraining's binary_logloss: 0.32539\ttraining's auc: 0.941003\n",
      "[2400]\ttraining's binary_logloss: 0.321652\ttraining's auc: 0.942887\n",
      "[2500]\ttraining's binary_logloss: 0.317994\ttraining's auc: 0.944702\n",
      "[2600]\ttraining's binary_logloss: 0.314344\ttraining's auc: 0.946481\n",
      "[2700]\ttraining's binary_logloss: 0.310804\ttraining's auc: 0.9482\n",
      "[2800]\ttraining's binary_logloss: 0.307557\ttraining's auc: 0.949755\n",
      "[2900]\ttraining's binary_logloss: 0.304147\ttraining's auc: 0.951368\n",
      "[3000]\ttraining's binary_logloss: 0.30086\ttraining's auc: 0.952892\n",
      "[3100]\ttraining's binary_logloss: 0.297657\ttraining's auc: 0.954382\n",
      "[3200]\ttraining's binary_logloss: 0.294481\ttraining's auc: 0.955804\n",
      "[3300]\ttraining's binary_logloss: 0.291395\ttraining's auc: 0.957188\n",
      "[3400]\ttraining's binary_logloss: 0.288325\ttraining's auc: 0.958562\n",
      "[3500]\ttraining's binary_logloss: 0.285305\ttraining's auc: 0.959886\n",
      "[3600]\ttraining's binary_logloss: 0.282453\ttraining's auc: 0.961116\n",
      "[3700]\ttraining's binary_logloss: 0.279602\ttraining's auc: 0.962342\n",
      "[3800]\ttraining's binary_logloss: 0.276793\ttraining's auc: 0.963522\n",
      "[3900]\ttraining's binary_logloss: 0.273967\ttraining's auc: 0.964703\n",
      "[4000]\ttraining's binary_logloss: 0.271285\ttraining's auc: 0.965817\n",
      "[4100]\ttraining's binary_logloss: 0.268608\ttraining's auc: 0.96689\n",
      "[4200]\ttraining's binary_logloss: 0.265999\ttraining's auc: 0.967958\n",
      "[4300]\ttraining's binary_logloss: 0.263363\ttraining's auc: 0.968987\n",
      "[4400]\ttraining's binary_logloss: 0.260807\ttraining's auc: 0.969972\n",
      "[4500]\ttraining's binary_logloss: 0.258337\ttraining's auc: 0.97091\n",
      "[4600]\ttraining's binary_logloss: 0.255812\ttraining's auc: 0.971878\n",
      "[4700]\ttraining's binary_logloss: 0.253404\ttraining's auc: 0.972766\n",
      "[4800]\ttraining's binary_logloss: 0.251015\ttraining's auc: 0.973651\n",
      "[4900]\ttraining's binary_logloss: 0.248658\ttraining's auc: 0.974519\n",
      "[5000]\ttraining's binary_logloss: 0.246319\ttraining's auc: 0.975346\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': ['binary_logloss', 'auc'],  \n",
    "\n",
    "    'learning_rate': 0.1,       \n",
    "    'num_leaves': 220,\n",
    "    'max_depth': 10,\n",
    "    'min_data_in_leaf': 500,     \n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 1,  \n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000,\n",
    "    'min_gain_to_split': 0,\n",
    "    'min_sum_hessian_in_leaf': 0.1,\n",
    "\n",
    "    'num_threads': 16,\n",
    "    'verbose': 0,\n",
    "    'is_training_metric': 'True'\n",
    "}\n",
    "\n",
    "print('Hyper-parameters:')\n",
    "print(params)\n",
    "\n",
    "MAX_ROUNDS = 5000\n",
    "evals_result = {}\n",
    "\n",
    "gbm = lgbm.train(params, train_data, num_boost_round=MAX_ROUNDS, evals_result=evals_result, valid_sets=train_data, verbose_eval=100)\n",
    "\n",
    "# 保存特征重要性\n",
    "feature_importance = pd.DataFrame({'name':gbm.feature_name(), 'importance':gbm.feature_importance()}).sort_values(by='importance', ascending=False)\n",
    "feature_importance.to_csv('./music_submission/four/feat_importance_for_test_0318_04.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. 模型的保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的模型\n",
    "import pickle as cPickle\n",
    "cPickle.dump(gbm, open(\"./music_submission/third/Music_LightGBM_0318_03.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "import pickle as cPickle\n",
    "gbm = cPickle.load(open(\"./music_submission/third/Music_LightGBM_0318_03.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 预测0-33%位置的测试集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_all\n",
    "# gc.collect()\n",
    "# 根据预测结果生成结果集\n",
    "val_auc = 0.971121\n",
    "# val_auc = 0.9753\n",
    "size_1 = math.ceil(test.shape[0] * 0.33)\n",
    "test_1 = test[0:size_1]\n",
    "test_id_1 = test_id[0:size_1]\n",
    "\n",
    "test_pred_1 = gbm.predict(test_1)\n",
    "test_sub_1 = pd.DataFrame({'id': test_id_1, 'target': test_pred_1})\n",
    "test_sub_1.to_csv('./music_submission/third/submission_lgb_%.5f_3_01.csv.gz'%(val_auc), index=False, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 预测33-66%位置的测试集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_1\n",
    "del test_id_1\n",
    "del test_pred_1\n",
    "gc.collect()\n",
    "\n",
    "size_2 = math.ceil(test.shape[0] * 0.66)\n",
    "test_2 = test[size_1:size_2]\n",
    "test_id_2 = test_id[size_1:size_2]\n",
    "\n",
    "test_pred_2 = gbm.predict(test_2)\n",
    "test_sub_2 = pd.DataFrame({'id': test_id_2, 'target': test_pred_2})\n",
    "test_sub_2.to_csv('./music_submission/third/submission_lgb_%.5f_3_02.csv.gz'%(val_auc), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 预测66%-100%位置的测试集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_2\n",
    "del test_id_2\n",
    "del test_pred_2\n",
    "gc.collect()\n",
    "\n",
    "test_3 = test[size_2:]\n",
    "test_id_3 = test_id[size_2:]\n",
    "\n",
    "test_pred_3 = gbm.predict(test_3)\n",
    "test_sub_3 = pd.DataFrame({'id': test_id_3, 'target': test_pred_3})\n",
    "test_sub_3.to_csv('./music_submission/third/submission_lgb_%.5f_3_03.csv.gz'%(val_auc), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 综合三次预测结果，保存最后的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.concat([test_sub_1, test_sub_2, test_sub_3], axis=0)\n",
    "test_sub.to_csv('./music_submission/third/submission_lgb_%.5f_3_123.csv'%(val_auc), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 读取四个训练好的模型预测的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/package')\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "a1 = pd.read_csv('./music_submission/first/submission_lgb_0.95696_1231.csv')\n",
    "a2 = pd.read_csv('./music_submission/second/submission_lgb_0.97015_2_123.csv')\n",
    "a3 = pd.read_csv('./music_submission/third/submission_lgb_0.97112_3_123.csv')\n",
    "a4 = pd.read_csv('./music_submission/four/submission_lgb_0.97530_4_123.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 对测试集预测结果做加权"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 只取后30%训练集训练模型，预测测试集提交Kaggle，public分数是0.70386\n",
    "2. 分别依次取10%-30%，30%-50%，50%-70%，70%-100%位置的训练集，进行了4次模型训练，并分别用这4个模型预测测试集，\n",
    "   对四个结果求平均，提交Kaggle，public分数0.70290\n",
    "3. 对四个模型训练结果做加权：提交Kaggle，public分数是0.70987\n",
    "\n",
    "   10%-30%：系数0.1\n",
    "   \n",
    "   30%-50%：系数0.1\n",
    "   \n",
    "   50%-70%：系数0.2\n",
    "   \n",
    "   70%-100%：系数0.6\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1['target'] = a1['target'] * 0.6 + a2['target'] * 0.2+ a3['target'] * 0.1 + a4['target'] * 0.1\n",
    "a1.to_csv('./music_submission/submission_lgb_1234_weight_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
