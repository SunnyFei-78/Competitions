{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "\n",
    "## 基础工具\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import jn\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "## 模型预测的\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "## 数据降维处理的\n",
    "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "\n",
    "## 参数搜索和评价的\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,StratifiedKFold,KFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "\n",
    "## 模型\n",
    "import pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## feature selection\n",
    "# feat_importance = pd.read_csv('./used_car/feat_importance/lightGBM_feat_importance_0403_v2.csv')\n",
    "# feature_name = feat_importance['name'].values\n",
    "# feature_importance = feat_importance['importance'].values\n",
    "\n",
    "# drop_col = feature_name[feature_importance<4000]\n",
    "# train.drop(drop_col, axis=1, inplace=True)\n",
    "# test.drop(drop_col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../training/train_data_180.csv')\n",
    "test = pd.read_csv('../training/test_data_180.csv')\n",
    "\n",
    "train_X = train.drop(['price','SaleID'], axis=1)\n",
    "train_y = train['price']\n",
    "test_X = test.drop(['SaleID'], axis=1)\n",
    "\n",
    "feat_name = train_X.columns\n",
    "\n",
    "# 交叉验证折数\n",
    "S_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用sklearn的train_test_split函数，随机划分验证集\n",
    "tr_X,val_X,tr_y,val_y = train_test_split(train_X,train_y,test_size=0.2, random_state=2000)\n",
    "\n",
    "# 用lightGBM模型时，数据需要转换成Dataset类型\n",
    "train_data_lgb = lgbm.Dataset(tr_X, label=tr_y, free_raw_data=True)\n",
    "val_data_lgb = lgbm.Dataset(val_X, label=val_y, free_raw_data=True)\n",
    "\n",
    "# 用XGBoost模型时，数据需要转换成DMatrix类型\n",
    "train_data_xgb = xgb.DMatrix(tr_X, label=tr_y)\n",
    "val_data_xgb = xgb.DMatrix(val_X, label=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义了一个统计函数，方便后续信息统计\n",
    "def Sta_inf(data):\n",
    "    print('_min',np.min(data))\n",
    "    print('_max:',np.max(data))\n",
    "    print('_mean',np.mean(data))\n",
    "    print('_ptp',np.ptp(data))\n",
    "    print('_std',np.std(data))\n",
    "    print('_var',np.var(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#lgb作为基模型的特征选择\n",
    "slt = SelectFromModel(lgbm.LGBMRegressor(n_estimators=3000)).fit(train_X, train_y)\n",
    "\n",
    "train_X = pd.DataFrame(slt.transform(train_X))\n",
    "test_X = pd.DataFrame(slt.transform(test_X))\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lr(x_train,y_train):\n",
    "    reg_model = linear_model.LinearRegression()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_lgb(x_train,y_train):\n",
    "    gbm = lgb.LGBMRegressor(n_estimators=8000, max_depth=10, num_leaves=85, min_data_in_leaf=5 ,subsample=0.9, colsample_bytree=0.8, \n",
    "                            learning_rate=0.05, feature_fraction=0.8,lambda_l1=1, lambda_l2=2, n_jobs=-1)\n",
    "    gbm.fit(x_train, y_train)\n",
    "    return gbm\n",
    "\n",
    "def build_model_xgb(x_train,y_train):\n",
    "    xgb_r = xgb.XGBRegressor(n_estimators=8000, learning_rate=0.05, max_depth=7, min_child_weight=3, subsample=0.9,\n",
    "                        colsample_bytree=0.7, reg_alpha=3, reg_lambda=5, n_jobs=-1)\n",
    "    xgb_r.fit(x_train, y_train)\n",
    "    return xgb_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 用XGBoost训练模型并预测测试集\n",
    "print('Training XGB...')\n",
    "model_xgb = build_model_xgb(tr_X,tr_y)\n",
    "\n",
    "print('Predict XGB...')\n",
    "val_xgb = model_xgb.predict(val_X)\n",
    "subA_xgb = np.expm1(model_xgb.predict(test_X))\n",
    "\n",
    "MAE_xgb = mean_absolute_error(np.expm1(val_y),np.expm1(val_xgb))\n",
    "print('MAE of val with xgb:',MAE_xgb)\n",
    "print('Status of Predict xgb:')\n",
    "Sta_inf(subA_xgb)\n",
    "\n",
    "## 用lightGBM训练模型并预测测试集\n",
    "print('Training lgb...')\n",
    "model_lgb = build_model_lgb(tr_X,tr_y)\n",
    "\n",
    "print('Predict lgb...')\n",
    "val_lgb = model_lgb.predict(val_X)\n",
    "subA_lgb = np.expm1(model_lgb.predict(test_X))\n",
    "\n",
    "MAE_lgb = mean_absolute_error(np.expm1(val_y),np.expm1(val_lgb))\n",
    "print('MAE of val with lgb:',MAE_lgb)\n",
    "print('Status of Predict lgb:')\n",
    "Sta_inf(subA_lgb)\n",
    "\n",
    "## 这里采取了简单的加权融合的方式\n",
    "val_Weighted = (1-MAE_lgb/(MAE_xgb+MAE_lgb))*val_lgb+(1-MAE_xgb/(MAE_xgb+MAE_lgb))*val_xgb\n",
    "val_Weighted[val_Weighted<0]=10 # 由于我们发现预测的最小值有负数，而真实情况下，price为负是不存在的，由此我们进行对应的后修正\n",
    "print('MAE of val with Weighted ensemble:',mean_absolute_error(y_val,val_Weighted))\n",
    "\n",
    "sub_Weighted = (1-MAE_lgb/(MAE_xgb+MAE_lgb))*subA_lgb+(1-MAE_xgb/(MAE_xgb+MAE_lgb))*subA_xgb\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = test.SaleID\n",
    "sub['price'] = sub_Weighted\n",
    "sub.to_csv('./used_car/submission/sub_Weighted_01.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 第一种融合方式 - 加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
    "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
    "    return Weighted_result\n",
    "\n",
    "# Init the Weight\n",
    "w = [0.3,0.4,0.3]\n",
    "\n",
    "# 测试验证集准确度\n",
    "val_pre = Weighted_method(val_lgb,val_xgb,val_gbdt,w)\n",
    "MAE_Weighted = mean_absolute_error(y_val,val_pre)\n",
    "print('MAE of Weighted of val:',MAE_Weighted)\n",
    "\n",
    "# 预测数据部分\n",
    "subA = Weighted_method(subA_lgb,subA_xgb,subA_gbdt,w)\n",
    "print('Sta inf:')\n",
    "Sta_inf(subA)\n",
    "\n",
    "# 生成提交文件\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = test.SaleID\n",
    "sub['price'] = subA\n",
    "sub.to_csv('../submission/sub_Weighted_128_0409_01.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 第二种融合方式 - 二层Stacking融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starking\n",
    "\n",
    "## 第一层\n",
    "train_lgb_pred = np.expm1(model_lgb.predict(tr_X))\n",
    "train_xgb_pred = np.expm1(model_xgb.predict(tr_X))\n",
    "# train_gbdt_pred = model_gbdt.predict(x_train)\n",
    "\n",
    "Strak_X_train = pd.DataFrame()\n",
    "Strak_X_train['Method_1'] = train_lgb_pred\n",
    "Strak_X_train['Method_2'] = train_xgb_pred\n",
    "# Strak_X_train['Method_3'] = train_gbdt_pred\n",
    "\n",
    "Strak_X_val = pd.DataFrame()\n",
    "Strak_X_val['Method_1'] = val_lgb\n",
    "Strak_X_val['Method_2'] = val_xgb\n",
    "# Strak_X_val['Method_3'] = val_gbdt\n",
    "\n",
    "Strak_X_test = pd.DataFrame()\n",
    "Strak_X_test['Method_1'] = subA_lgb\n",
    "Strak_X_test['Method_2'] = subA_xgb\n",
    "# Strak_X_test['Method_3'] = subA_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## level2-method \n",
    "model_lr_Stacking = build_model_lr(Strak_X_train,tr_y)\n",
    "## 训练集\n",
    "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error((tr_y),np.expm1(train_pre_Stacking))\n",
    "\n",
    "## 验证集\n",
    "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(np.expm1(val_y),np.expm1(val_pre_Stacking))\n",
    "\n",
    "## 预测集\n",
    "print('Predict Stacking-LR...')\n",
    "subA_Stacking = np.expm1(model_lr_Stacking.predict(Strak_X_test))\n",
    "\n",
    "subA_Stacking[subA_Stacking<10]=10  ## 去除过小的预测值\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = test.SaleID\n",
    "sub['price'] = subA_Stacking\n",
    "sub.to_csv('../submission/sub_Stacking.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
