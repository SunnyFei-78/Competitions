{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型调优过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "\n",
    "## 基础工具\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import jn\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "## 模型预测的\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "## 数据降维处理的\n",
    "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
    "\n",
    "# import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "## 参数搜索和评价的\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../training/train_data_180.csv')\n",
    "test = pd.read_csv('../training/test_data_180.csv')\n",
    "\n",
    "train_X = train.drop(['price','SaleID'], axis=1)\n",
    "train_y = train['price']\n",
    "test_X = test.drop(['SaleID'], axis=1)\n",
    "\n",
    "feat_name = train_X.columns\n",
    "\n",
    "# 交叉验证折数\n",
    "S_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBM这里的y，用的是log1p变换后的y\n",
    "tr_X,val_X,tr_y,val_y = train_test_split(train_X,train_y,test_size=0.2, random_state=2000)\n",
    "\n",
    "# 用lightGBM模型时，数据需要转换成Dataset类型\n",
    "train_data_lgb = lgbm.Dataset(tr_X, label=tr_y, free_raw_data=True)\n",
    "val_data_lgb = lgbm.Dataset(val_X, label=val_y, free_raw_data=True)\n",
    "\n",
    "## 定义了一个统计函数，方便后续信息统计\n",
    "def Sta_inf(data):\n",
    "    print('_min',np.min(data))\n",
    "    print('_max:',np.max(data))\n",
    "    print('_mean',np.mean(data))\n",
    "    print('_ptp',np.ptp(data))\n",
    "    print('_std',np.std(data))\n",
    "    print('_var',np.var(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost这里的y，用的是原始y\n",
    "tr_X,val_X,tr_y,val_y = train_test_split(train_X,np.expm1(train_y),test_size=0.2, random_state=2000)\n",
    "\n",
    "# 用XGBoost模型时，数据需要转换成DMatrix类型\n",
    "train_data_xgb = xgb.DMatrix(tr_X, label=tr_y)\n",
    "val_data_xgb = xgb.DMatrix(val_X, label=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 62, 50000, 62)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape + test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型一: LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = linear_model.LinearRegression()\n",
    "model_lr = model_lr.fit(train_X, train_y)\n",
    "\n",
    "feat_name = train_X.columns\n",
    "\n",
    "print('intercept:'+ str(model_lr.intercept_))\n",
    "sorted(dict(zip(feat_name, model_lr.coef_)).items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2388.74333435, 2407.09506836, 2425.05182767, 2375.28063236,\n",
       "       2398.05819435])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error,  make_scorer\n",
    "\n",
    "scores = cross_val_score(model_lr, X=train_X, y=train_y, verbose=1, cv = 5, scoring=make_scorer((mean_absolute_error)))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 2398.845811420034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2388.743334</td>\n",
       "      <td>2407.095068</td>\n",
       "      <td>2425.051828</td>\n",
       "      <td>2375.280632</td>\n",
       "      <td>2398.058194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cv1          cv2          cv3          cv4          cv5\n",
       "MAE  2388.743334  2407.095068  2425.051828  2375.280632  2398.058194"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('AVG:', np.mean(scores))\n",
    "\n",
    "scores = pd.DataFrame(scores.reshape(1,-1))\n",
    "scores.columns = ['cv' + str(x) for x in range(1, 6)]\n",
    "scores.index = ['MAE']\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762.6133193969727"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_point = len(train) // 5 * 4\n",
    "train = train.loc[:split_point].dropna()\n",
    "val = train.loc[split_point:].dropna()\n",
    "\n",
    "train_X = train.drop(['price','train'], axis=1)\n",
    "train_y = train['price']\n",
    "val_X = val.drop(['price','train'], axis=1)\n",
    "val_y = val['price']\n",
    "\n",
    "model_LR = linear_model.LinearRegression()\n",
    "\n",
    "model_LR = model_LR.fit(train_X, train_y)\n",
    "mean_absolute_error(val_y, model_LR.predict(val_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型二：随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of each fold is:  [685.07658014 673.26679167 676.18096667 679.44129583 684.36042917]\n",
      "cv MAE is: 679.6652126951655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF1 = RandomForestRegressor()\n",
    "\n",
    "# 交叉验证用于评估模型性能和进行参数调优（模型选择）\n",
    "#分类任务中交叉验证缺省是采用StratifiedKFold\n",
    "#数据集不大，采用3折交叉验证\n",
    "mae = cross_val_score(RF1, train_X, train_y, cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print ('MAE of each fold is: ', mae)\n",
    "print('cv MAE is:', mae.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果看，默认的随机森林MAE分值（679.665）比线性模型（726.613）低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>685.076580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>673.266792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>676.180967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>679.441296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv5</th>\n",
       "      <td>684.360429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "cv1  685.076580\n",
       "cv2  673.266792\n",
       "cv3  676.180967\n",
       "cv4  679.441296\n",
       "cv5  684.360429"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(mae)\n",
    "result.index = ['cv' + str(x) for x in range(1, 6)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv1</th>\n",
       "      <th>cv2</th>\n",
       "      <th>cv3</th>\n",
       "      <th>cv4</th>\n",
       "      <th>cv5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>685.07658</td>\n",
       "      <td>673.266792</td>\n",
       "      <td>676.180967</td>\n",
       "      <td>679.441296</td>\n",
       "      <td>684.360429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cv1         cv2         cv3         cv4         cv5\n",
       "MAE  685.07658  673.266792  676.180967  679.441296  684.360429"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = pd.DataFrame(mae.reshape(1,-1))\n",
    "mae.columns = ['cv' + str(x) for x in range(1, 6)]\n",
    "mae.index = ['MAE']\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林的超参会有很多：\n",
    "Bagging参数：\n",
    "1. 树的数目n_estimators\n",
    "\n",
    "与决策树的共同的超参数：\n",
    "1. max_depth（树的深度）或max_leaf_nodes（叶子结点的数目）；\n",
    "2. min_samples_leaf（叶子结点的最小样本数）、min_samples_split（中间结点的最小样本树）、min_weight_fraction_leaf（叶子节点的样本权重占总权重的比例）\n",
    "3. max_features（最大特征数目）。与决策树max_features通常越大模型性能越好不同，随机森林中max_features较小，每个基学习器之间的相关性更小，集成模型的性能可能反而会更好；\n",
    "\n",
    "另外在随机森林中，由于学习每个基学习器只用了一部分样本，可用其余样本（包外样本）做校验，从而不必显式进行交叉验证。\n",
    "设置参数oob_score=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数 n_estimators\n",
    "tuned_n_estimators = range(50,300,50)\n",
    "accuracy_s = np.zeros(len(tuned_n_estimators))\n",
    "\n",
    "#初始max_depth设为单棵树的max_depth，max_features比推荐值sqrt(D)略大,\n",
    "#min_samples_leaf比单棵树的min_samples_leaf略小（详见CART参数调优）\n",
    "for j, one_n_estimators in enumerate(tuned_n_estimators):\n",
    "    RF2 = RandomForestRegressor(criterion= 'mae', n_estimators = one_n_estimators, max_depth =10, max_features = 10, min_samples_leaf=2,oob_score=True,n_jobs=-1,random_state=33)\n",
    "    RF2.fit(train_X, train_y)\n",
    "    accuracy_s[j] = RF2.oob_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tuned_n_estimators, accuracy_s)\n",
    "plt.xlabel('n_estimators' )                                                                                                      \n",
    "plt.ylabel('R2 score' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_features(在上一步参数确定的前提下)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turned_params = range(10, 40, 2)\n",
    "r2_scores = np.zeros(len(turned_params))\n",
    "\n",
    "for j, one_para in enumerate(turned_params):\n",
    "    RF2 = RandomForestRegressor(n_estimators = 200, criterion = 'mae', max_depth=10, min_sample_leaf=2, oob_score=True, \n",
    "                               verbose=10, n_jobs=-1, random_state=33)\n",
    "    RF2.fit(train_X, train_y)\n",
    "    r2_scores[j] = RF2.oob_score_ \n",
    "    \n",
    "plt.plot(turned_params, r2_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('R2 score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_depth (在上一步参数确定的前提下)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turned_params = range(10, 50, 5)\n",
    "r2_scores = np.zeros(len(turned_params))\n",
    "\n",
    "for j, one_para in enumerate(turned_params):\n",
    "    RF2 = RandomForestRegressor(n_estimators=200, max_features=, min_sample_leaf=20, oob_socre=True, \n",
    "                                n_jobs=-1, random_state=33, verbose=10)\n",
    "    RF2.fit(train_X, train_y)\n",
    "    r2_scores[j] = oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_samples_leaf (在上一步参数确定的前提下)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turned_params = range(1, 10, 2)\n",
    "r2_scores = np.zeros(len(turned_params))\n",
    "\n",
    "for j, one_para in enumerate(turned_params):\n",
    "    RF2 = RandomForestRegressor(n_estimators=200, max_features=, max_depth = , oob_socre=True, \n",
    "                                n_jobs=-1, random_state=33, verbose=10)\n",
    "    RF2.fit(train_X, train_y)\n",
    "    r2_scores[j] = oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用最佳参数组合，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF2 = RandomForestRegressor(n_estimators=200, max_features=, max_depth = , oob_socre=True, \n",
    "                                n_jobs=-1, random_state=33, verbose=10)\n",
    "RF2.fit(train_X, train_y)\n",
    "feat_names = X_train.columns \n",
    "\n",
    "import pickle\n",
    "pickle.dump(RF2, open('./RandomForestRegressor_V1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'columns': list(feat_names), 'importance': list(RF2.feature_importances_.T)})\n",
    "df = df.sort_values(by=['importance'], ascending=False)\n",
    "plt.bar(range(len(RF2.feature_importances_)), RF2.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型三： XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost的主要超参数包括：\n",
    "1. 树的数目n_estimators 和 学习率 learning_rate\n",
    "2. 树的最大深度max_depth\n",
    "3. 叶子结点的最小样本数:min_child_weight\n",
    "4. 每棵树的列采样比例：colsample_bytree\n",
    "5. 每棵树的行采样比例：subsample\n",
    "6. 正则化参数lambda_l1(reg_alpha), lambda_l2(reg_lambda)\n",
    "\n",
    "对n_estimators，XGBoost学习的过程内嵌了cv，速度快。\n",
    "其他参数用GridSearchCV。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1：学习率为0.1，粗调基学习器的数目n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 10000\n",
    "params = {\n",
    "          'eval_metric':'mae'，\n",
    "          'objective': 'reg:squarederror',\n",
    "          'learning_rate': 0.1,\n",
    "          #'n_estimators': 1000\n",
    "          'min_child_weight': 1,\n",
    "          'max_depth': 7,\n",
    "          'subsample': 0.8,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'n_jobs': -1,   \n",
    "\n",
    "         }\n",
    "\n",
    "#直接调用xgboost内嵌的交叉验证（cv），可对连续的n_estimators参数进行快速交叉验证，GridSearchCV只能对有限个参数进行交叉验证\n",
    "def get_n_estimators(params, X_train , y_train , early_stopping_rounds=10):\n",
    "    xgb_params = params.copy()\n",
    "    \n",
    "    #直接调用xgboost，而非sklarn的wrapper类\n",
    "    xgb_train = xgb.DMatrix(X_train, label = y_train)\n",
    "        \n",
    "    cv_result = xgb.cv(xgb_params, xgb_train, num_boost_round=MAX_ROUNDS, nfold=3,\n",
    "             metrics='mae', early_stopping_rounds=early_stopping_rounds,seed=3)\n",
    "  \n",
    "    cv_result.to_csv('./xgb_n_estimators_v1.csv', index_label = 'n_estimators')\n",
    "    \n",
    "    #最佳参数n_estimators\n",
    "    n_estimators = cv_result.shape[0]\n",
    "    print('best n_estimators:' , n_estimators)\n",
    "    print('best cv score:' , cv_result['test-mae-mean'][n_estimators-1])\n",
    "     \n",
    "    return n_estimators\n",
    "\n",
    "n_estimators_1 = get_n_estimators(params , train_X , train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step2：调整树的参数：max_depth & min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两个参数尽可能一起调，因为max_depth和min_child_weight都直接影响树模型的复杂度。\n",
    "如果计算资源有限，也可类似坐标轴下降，先调其中一个，然后调另一个。\n",
    "如果是分类任务，且不同类的样本数目不均衡，最好先调min_child_weight，以免max_depth对少数类样本过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth 建议3-10， min_child_weight=1／sqrt(ratio_rare_event) =5.5\n",
    "max_depth = range(5,10,2)\n",
    "min_child_weight = range(1,6,2)\n",
    "tuned_params = dict(max_depth=max_depth, min_child_weight=min_child_weight)\n",
    "\n",
    "params = {\n",
    "          'objective': 'reg:squarederror',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators': n_estimators_1,   #第一轮参数调整得到的n_estimators最优值\n",
    "#           'min_child_weight': 3,\n",
    "#           'max_depth': 5,\n",
    "          'subsample': 0.8,\n",
    "          'colsample_bytree': 0.9,\n",
    "          'nthread': 8\n",
    "         }\n",
    "\n",
    "xgb_g = XGBRegressor(silent=False,  **params)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_g, param_grid = tuned_params, scoring=make_scorer((mean_absolute_error)),\n",
    "                           n_jobs=-1, cv=kfold,verbose=5, refit = False)\n",
    "grid_search.fit(train_X , train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
    "test_means = grid_search.cv_results_['mean_test_score']\n",
    "test_stds = grid_search.cv_results_['std_test_score']\n",
    "train_means = grid_search.cv_results_['mean_train_score']\n",
    "train_stds = grid_search.cv_results_['std_train_score']\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_).to_csv('max_depth_min_child_weights_1.csv')\n",
    "\n",
    "# plot results\n",
    "test_scores = np.array(test_means).reshape(len(max_depth), len(min_child_weight))\n",
    "train_scores = np.array(train_means).reshape(len(max_depth), len(min_child_weight))\n",
    "\n",
    "for i, value in enumerate(max_depth):\n",
    "    plt.plot(min_child_weight, -test_scores[i], label= 'test_max_depth:'   + str(value))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('min_child_weight' )                                                                                                      \n",
    "plt.ylabel('Loss' )\n",
    "plt.savefig('max_depth_and_min_child_weght_1.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step3：行采样比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_s = [i/10.0 for i in range(5,10)]\n",
    "tuned_params = dict(subsample=subsample_s)\n",
    "\n",
    "params = {'objective': 'reg:squarederror',\n",
    "        #   'learning_rate': 0.1,\n",
    "          'n_estimators': 1750,   #第一轮参数调整得到的n_estimators最优值\n",
    "          'min_child_weight': 3,\n",
    "          'max_depth': 10,\n",
    "          'subsample': 0.9,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'nthread': 8\n",
    "         }\n",
    "\n",
    "xgb_g = xgb.XGBRegressor(silent=False,  **params)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_g, param_grid = tuned_params, scoring=make_scorer(mean_absolute_error),n_jobs=-1, \\\n",
    "                      cv=kfold,verbose=5, refit = False)\n",
    "grid_search.fit(train_X , train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
    "test_means = grid_search.cv_results_[ 'mean_test_score' ]\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_).to_csv('subsample.csv')\n",
    "\n",
    "plt.plot(subsample_s, -test_means)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('subsample' )                                                                                                      \n",
    "plt.ylabel('Loss' )\n",
    "plt.savefig('subsample.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step4：列采样比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsample_bytree_s = [i/10.0 for i in range(5,10)]\n",
    "tuned_params = dict(colsample_bytree=colsample_bytree_s)\n",
    "\n",
    "params = {'objective': 'reg:squarederror',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators': 1750,   #第一轮参数调整得到的n_estimators最优值\n",
    "          'min_child_weight': 3,\n",
    "          'max_depth': 10,\n",
    "          'subsample': 0.9,\n",
    "#           'colsample_bytree': 0.8,\n",
    "          'nthread': 8\n",
    "         }\n",
    "\n",
    "xgb_g = xgb.XGBRegressor(silent=False,  **params)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_g, param_grid = tuned_params, scoring=make_scorer(mean_absolute_error),\n",
    "                           n_jobs=-1, cv=kfold, verbose=5, refit = False)\n",
    "grid_search.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
    "test_means = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_).to_csv('colsample_bytree.csv')\n",
    "\n",
    "plt.plot(colsample_bytree_s, test_means)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('colsample_bytree')                                                                                                      \n",
    "plt.ylabel('Loss' )\n",
    "plt.savefig('colsample_bytree.png' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step5. 用树的最佳参数，再次调整学习率和基学习器的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用所有训练好的参数，降低学习率，调整基学习器数目。这里设置了0.05\n",
    "params = {\n",
    "          'learning_rate': 0.05,\n",
    "        #   'n_estimators': 1750, \n",
    "          'min_child_weight': 3,\n",
    "          'max_depth': 10,\n",
    "          'subsample': 0.9,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'reg_lambda':5,\n",
    "          'reg_alpha':3,\n",
    "          'nthread': 8\n",
    "}\n",
    "\n",
    "n_estimators_2 = get_n_estimators(params, X_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step6. 用所有训练数据，采用最佳参数重新训练模型\n",
    "由于样本数目增多，模型复杂度稍微扩大一点？\n",
    "max_depth增多1\n",
    "min_child_weight按样本比例,从3增加到4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'learning_rate': 0.01,\n",
    "          'n_estimators': 7000, \n",
    "          'min_child_weight': 3,\n",
    "          'max_depth': 10,\n",
    "          'subsample': 0.9,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'reg_lambda':5,\n",
    "          'reg_alpha':3,\n",
    "          'nthread': 8\n",
    "         }\n",
    "        \n",
    "xgb_r = xgb.XGBRegressor(silent=False, **params)\n",
    "xgb_r.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step8. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb_r, open(\"./used_car/model/used_car_XGBoost_v1.pkl\", 'wb'))\n",
    "\n",
    "df = pd.DataFrame({\"columns\":list(feat_name), \"importance\":list(xgb_r.feature_importances_.T)})\n",
    "df = df.sort_values(by=['importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型四：LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要超参包括：\n",
    "1. 树的数目n_estimators 和 学习率 learning_rate\n",
    "2. 树的最大深度max_depth 和 树的最大叶子节点数目num_leaves（注意：XGBoost只有max_depth，LightGBM采用叶子优先的方式生成树，num_leaves很重要，设置成比 2^max_depth 小）\n",
    "3. 叶子结点的最小样本数:min_data_in_leaf(min_data, min_child_samples)\n",
    "4. 每棵树的列采样比例：feature_fraction/colsample_bytree\n",
    "5. 每棵树的行采样比例：bagging_fraction （需同时设置bagging_freq=1）/subsample\n",
    "6. 正则化参数lambda_l1(reg_alpha), lambda_l2(reg_lambda)\n",
    "\n",
    "7. 两个非模型复杂度参数，但会影响模型速度和精度。可根据特征取值范围和样本数目修改这两个参数\n",
    "1）特征的最大bin数目max_bin：默认255；\n",
    "2）用来建立直方图的样本数目subsample_for_bin：默认200000。\n",
    "\n",
    "对n_estimators，用LightGBM内嵌的cv函数调优，因为同XGBoost一样，LightGBM学习的过程内嵌了cv，速度极快。\n",
    "其他参数用GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1. 先调试estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "MAX_ROUNDS = 1000\n",
    "\n",
    "#调用lightgbm内嵌的交叉验证(cv)，可对连续的n_estimators参数进行快速交叉验证， GridSearchCV只能对有限个参数进行交叉验证速度相对较慢\n",
    "def get_n_estimators(params , X_train , y_train , early_stopping_rounds=10):\n",
    "    lgbm_params = params.copy()\n",
    "    lgbmtrain = lgbm.Dataset(X_train , y_train )\n",
    "     \n",
    "    cv_result = lgbm.cv(lgbm_params , lgbmtrain , num_boost_round=MAX_ROUNDS , nfold=3,  metrics='mse' , early_stopping_rounds=early_stopping_rounds,seed=3 )\n",
    "     \n",
    "    print('best n_estimators:' , len(cv_result['mse-mean']))\n",
    "    print('best cv score:' , cv_result['mse-mean'][-1])\n",
    "     \n",
    "    return len(cv_result['mse-mean'])\n",
    "\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'num_leaves': 60,\n",
    "          'max_depth': 6,\n",
    "          'max_bin': 255,\n",
    "          'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,\n",
    "          'n_jobs': -1,\n",
    "         }\n",
    "\n",
    "n_estimators_1 = get_n_estimators(params , train_X , train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step2. num_leaves & max_depth=7\n",
    "num_leaves建议70-80，搜索区间50-80,值越大模型越复杂，越容易过拟合\n",
    "相应的扩大max_depth=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators':n_estimators_1,\n",
    "          'max_depth': 7,\n",
    "          'max_bin': 255,     \n",
    "          'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,  \n",
    "          'n_jobs': -1,\n",
    "         }\n",
    "lg = LGBMRegressor(silent=False,  **params)\n",
    "\n",
    "num_leaves_s = range(50,90,10)\n",
    "tuned_parameters = dict( num_leaves = num_leaves_s)\n",
    "\n",
    "grid_search = GridSearchCV(lg, param_grid=tuned_parameters, cv = kfold, scoring=make_scorer(mean_absolute_error)), \n",
    "                                  verbose=5, refit = False)\n",
    "grid_search.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(-grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CV误差曲线\n",
    "test_means = grid_search.cv_results_[ 'mean_test_score' ]\n",
    "test_stds = grid_search.cv_results_[ 'std_test_score' ]\n",
    "train_means = grid_search.cv_results_[ 'mean_train_score' ]\n",
    "train_stds = grid_search.cv_results_[ 'std_train_score' ]\n",
    "\n",
    "n_leafs = len(num_leaves_s)\n",
    "\n",
    "x_axis = num_leaves_s\n",
    "plt.plot(x_axis, -test_means)\n",
    "plt.errorbar(x_axis, -test_means, yerr=test_stds,label =' Test')\n",
    "plt.errorbar(x_axis, -train_means, yerr=train_stds,label = ' Train')\n",
    "plt.xlabel('num_leaves' )\n",
    "plt.ylabel('Loss' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step3. min_data_in_leaf\n",
    "叶子节点的最小样本数目\n",
    "\n",
    "搜索范围：10-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective':'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators': n_estimators_1,\n",
    "          'max_depth': 7,\n",
    "          'max_bin': 255,\n",
    "          'num_leaves': 70,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,\n",
    "          'n_jobs': -1\n",
    "}\n",
    "\n",
    "lg = LGBMRegressor(silent=False, **params)\n",
    "\n",
    "min_data_leaf_s = range(10, 100, 10)\n",
    "turned_parameters = dict(min_data_in_leaf = min_data_in_leaf_s)\n",
    "\n",
    "grid_search = GridSearchCV(lg, param_grid = params, cv = kfold, scoring = make_scorer(mean_absolute_error),\n",
    "                           verbose=5, refit=False, n_jobs=-1)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CV误差曲线\n",
    "test_means = grid_search.cv_results_['mean_test_score']\n",
    "test_stds = grid_search.cv_results_['std_test_score']\n",
    "train_means = grid_search.cv_results_['mean_train_score']\n",
    "train_stds = grid_search.cv_results_['std_train_score']\n",
    "\n",
    "n_leafs = len(num_leaves_s)\n",
    "\n",
    "x_axis = num_leaves_s\n",
    "plt.plot(x_axis, -test_means)\n",
    "#plt.errorbar(x_axis, -test_means, yerr=test_stds,label = ' Test')\n",
    "#plt.errorbar(x_axis, -train_means, yerr=train_stds,label = ' Train')\n",
    "plt.xlabel('num_leaves' )\n",
    "plt.ylabel('Loss' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step4: 行采样参数 sub_samples/bagging_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective':'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators': n_estimators_1,\n",
    "          'max_depth': 7,\n",
    "          'max_bin': 255,\n",
    "          'num_leaves': 70,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'feature_fraction': 0.8,\n",
    "          #'subsample': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,\n",
    "          'n_jobs': -1\n",
    "}\n",
    "\n",
    "lg = LGBMRegressor(silent=False,  **params)\n",
    "\n",
    "subsample_s = [i/10.0 for i in range(5,10)]\n",
    "tuned_parameters = dict( subsample = subsample_s)\n",
    "\n",
    "grid_search = GridSearchCV(lg, param_grid=tuned_parameters, cv = kfold, scoring=make_scorer(mean_absolute_error), \n",
    "                           n_jobs=-1,  verbose=5, refit = False)\n",
    "grid_search.fit(train_X , train_y)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CV误差曲线\n",
    "test_means = grid_search.cv_results_['mean_test_score']\n",
    "test_stds = grid_search.cv_results_['std_test_score']\n",
    "train_means = grid_search.cv_results_['mean_train_score']\n",
    "train_stds = grid_search.cv_results_['std_train_score']\n",
    "\n",
    "x_axis = subsample_s\n",
    "\n",
    "plt.plot(x_axis, -test_means)\n",
    "#plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i] ,label = str(max_depths[i]) +' Test')\n",
    "#plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i] ,label = str(max_depths[i]) +' Train')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step5. 列采样参数 feature_fraction/colsample_bytree/sub_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective':'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators': n_estimators_1,\n",
    "          'max_depth': 7,\n",
    "          'max_bin': 255,\n",
    "          'num_leaves': 70,\n",
    "          'min_data_in_leaf': 50,\n",
    "          #'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,\n",
    "          'n_jobs': -1\n",
    "}\n",
    "lg = LGBMRegressor(silent=False,  **params)\n",
    "\n",
    "colsample_bytree_s = [i/10.0 for i in range(5,10)]\n",
    "tuned_parameters = dict(colsample_bytree = colsample_bytree_s)\n",
    "\n",
    "grid_search = GridSearchCV(lg, param_grid=tuned_parameters, cv = kfold, scoring=make_scorer(mean_absolute_error), \n",
    "                            n_jobs=-1, verbose=5, refit = False)\n",
    "grid_search.fit(train_X , train_y)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CV误差曲线\n",
    "test_means = grid_search.cv_results_['mean_test_score']\n",
    "test_stds = grid_search.cv_results_['std_test_score']\n",
    "train_means = grid_search.cv_results_['mean_train_score']\n",
    "train_stds = grid_search.cv_results_['std_train_score']\n",
    "\n",
    "x_axis = colsample_bytree_s\n",
    "\n",
    "plt.plot(x_axis, -test_means)\n",
    "#plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i] ,label = str(max_depths[i]) +' Test')\n",
    "#plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i] ,label = str(max_depths[i]) +' Train')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step6. 减小学习率，调整n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective':'regression',\n",
    "          'learning_rate': 0.05,\n",
    "#           'n_estimators': n_estimators_1,\n",
    "          'max_depth': 7,\n",
    "          'max_bin': 255,\n",
    "          'num_leaves': 70,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,\n",
    "          'n_jobs': -1\n",
    "}\n",
    "n_estimators_2 = get_n_estimators(params , train_X , train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step7. 用所有训练数据，采用最佳参数重新训练模型\n",
    "由于样本数目增多，模型复杂度稍微扩大一点？\n",
    "num_leaves增多5\n",
    "min_child_samples按样本比例增加到40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective':'regression',\n",
    "          'learning_rate': 0.1,\n",
    "          'n_estimators': n_estimators_2,\n",
    "          'max_depth': 7,\n",
    "          'max_bin': 255,\n",
    "          'num_leaves': 70,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_freq': 1,  \n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 2,\n",
    "          'n_jobs': -1\n",
    "}\n",
    "\n",
    "lg = LGBMRegressor(silent=False,  **params)\n",
    "lg.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step8. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(lg, open(\"Otto_LightGBM_org_tfidf.pkl\", 'wb'))\n",
    "\n",
    "df = pd.DataFrame({\"columns\":list(feat_names), \"importance\":list(lg.feature_importances_.T)})\n",
    "df = df.sort_values(by=['importance'],ascending=False)\n",
    "\n",
    "plt.bar(range(len(lg.feature_importance_)), lg.feature_importance_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step9. 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型, 预测测试集结果，并保存\n",
    "import pickle as cPickle\n",
    "gbm = cPickle.load(open(\"../model/used_car_LightGBM_v2.pkl\", 'rb'))\n",
    "\n",
    "test_pred = gbm.predict(test_X)\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = test_X.SaleID\n",
    "sub['price'] = test_pred\n",
    "sub.to_csv('../submission/submission_lgb_02.csv',index=False)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
