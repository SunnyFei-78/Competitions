{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (150000, 31)\n",
      "TestA data shape: (50000, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/csdn/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('../data/source/usedcar_train.csv', sep=\" \")\n",
    "test = pd.read_csv('../data/source/usedcar_test.csv', sep=\" \")\n",
    "\n",
    "train['price'] = np.log1p(train['price'])\n",
    "print('Train data shape:',train.shape)\n",
    "print('TestA data shape:',test.shape)\n",
    "\n",
    "#合并数据集\n",
    "data = pd.concat([train, test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 特征基本统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['regDate', 'creatDate']\n",
    "cate_cols = ['name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox', 'notRepairedDamage', 'regionCode', 'seller', 'offerType']\n",
    "num_cols = ['power', 'kilometer'] + ['v_{}'.format(i) for i in range(15)]\n",
    "cols = date_cols + cate_cols + num_cols\n",
    "\n",
    "tmp = pd.DataFrame()\n",
    "tmp['count'] = data[cols].count().values\n",
    "tmp['missing_rate'] = (data.shape[0] - tmp['count']) / data.shape[0]\n",
    "tmp['nunique'] = data[cols].nunique().values\n",
    "tmp['max_value_counts'] = [data[f].value_counts().values[0] for f in cols]\n",
    "tmp['max_value_counts_prop'] = tmp['max_value_counts'] / data.shape[0]\n",
    "tmp['max_value_counts_value'] = [data[f].value_counts().index[0] for f in cols]\n",
    "tmp.index = cols\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 处理power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理异常值\n",
    "def smooth_cols(group,cols = ['power'],out_value = 600):\n",
    "    for col in cols:\n",
    "        yes_no = (group[col]<out_value).astype('int')\n",
    "        new = yes_no * group[col]\n",
    "        group[col] = new.replace(0,group[col].median())\n",
    "    return group\n",
    "\n",
    "data = data.groupby('brand').apply(smooth_cols,cols = ['power'],out_value = 600)\n",
    "data.index = range(len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.   处理时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#提取日期信息\n",
    "date_cols = ['regDate', 'creatDate']\n",
    "\n",
    "# data.loc[data['regDate'] == 20070009]\n",
    "# 使用时间：data['creatDate'] - data['regDate']，反应汽车使用时间，一般来说价格与使用时间成反比\n",
    "# 数据里有时间出错的格式，需要加errors='coerce'\n",
    "data['used_time_days'] = (pd.to_datetime(data['creatDate'], format='%Y%m%d', errors='coerce') - \n",
    "                            pd.to_datetime(data['regDate'], format='%Y%m%d', errors='coerce')).dt.days\n",
    "data['used_time_month'] = round(data['used_time_days'] / 30, 3)\n",
    "data['used_time_year'] = round(data['used_time_days'] / 365, 3)\n",
    "\n",
    "def date_proc(x):\n",
    "    m = int(x[4:6])\n",
    "    if m == 0:\n",
    "        m = 1\n",
    "    return x[:4] + '-' + str(m) + '-' + x[6:]\n",
    "\n",
    "for col in tqdm(date_cols):\n",
    "    data[col] = pd.to_datetime(data[col].astype('str').apply(date_proc))\n",
    "    data[col + '_year'] = data[col].dt.year\n",
    "    data[col + '_month'] = data[col].dt.month\n",
    "    data[col + '_day'] = data[col].dt.day\n",
    "    data[col + '_dayofweek'] = data[col].dt.dayofweek\n",
    "    \n",
    "# 增加新特征，成交日期是否是周末\n",
    "data['is_weekend'] = data['creatDate_dayofweek'].apply(lambda x: 1 if x in(5,6) else 0)\n",
    "\n",
    "# 使用年限折旧\n",
    "def depreciation_year(year):\n",
    "    if year <= 3:\n",
    "        return 1 - year * 0.15\n",
    "    elif year > 3 and  year <= 7:\n",
    "        return 0.55 - (year-3) * 0.1\n",
    "    elif year > 7 and  year <= 10:\n",
    "        return 0.25 - (year-7) * 0.05\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['depreciation_year'] = data['used_time_year'].apply(lambda x: depreciation_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat data shape: (200000, 44)\n"
     ]
    }
   ],
   "source": [
    "# 将2及之后fuelType的都归为2\n",
    "# Train_data.loc[Train_data['fuelType'] >= 2,'fuelType'] = 2 #用这个代码会直接把空值也变成2\n",
    "data.loc[data['fuelType'] == 3,'fuelType'] = 2 \n",
    "data.loc[data['fuelType'] == 4,'fuelType'] = 2 \n",
    "data.loc[data['fuelType'] == 5,'fuelType'] = 2 \n",
    "data.loc[data['fuelType'] == 6,'fuelType'] = 2 \n",
    "data['fuelType'].value_counts()\n",
    "\n",
    "data['notRepairedDamage'].replace('-', '2.0', inplace=True)\n",
    "print('concat data shape:',data.shape)\n",
    "\n",
    "# 对类别较少的特征采用one-hot编码\n",
    "# one_hot_list = ['fuelType','gearbox','notRepairedDamage']\n",
    "# for col in one_hot_list:\n",
    "#     one_hot = pd.get_dummies(data[col])\n",
    "#     one_hot.columns = [col+'_'+str(i) for i in range(len(one_hot.columns))]\n",
    "#     data = pd.concat([data,one_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                  1\n",
       "bodyType            5919\n",
       "gearbox             7891\n",
       "fuelType           11573\n",
       "used_time_days     15101\n",
       "used_time_month    15101\n",
       "used_time_year     15101\n",
       "price              50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = data.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['notRepairedDamage'].replace('-', 2.0, inplace=True)\n",
    "\n",
    "features = ['model','bodyType','fuelType','gearbox']\n",
    "for fe in features:\n",
    "    data[fe].fillna(data[fe].mode()[0], inplace=True)\n",
    "    train[fe].fillna(data[fe].mode()[0], inplace=True)\n",
    "    test[fe].fillna(data[fe].mode()[0], inplace=True)\n",
    "    \n",
    "features = ['used_time_days','used_time_month','used_time_year']\n",
    "for fe in features:\n",
    "    data[fe].fillna(data[fe].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 提取城市，年平均里程和独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从邮编中提取城市信息，相当于加入了先验知识\n",
    "data['city'] = data['regionCode'].apply(lambda x : str(x)[:-3])\n",
    "data['city'].replace('', 0, inplace=True)\n",
    "\n",
    "# 计算年平均里程， 即kilometer/汽车使用年限\n",
    "data['kilometer_everyear'] = round(1000 * data['kilometer'] / data['used_time_year'],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 统计特征在数据集里出现次数，代表热门程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 72.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# count编码\n",
    "def count_features(df, feat_cols):\n",
    "    for feat in tqdm(feat_cols):\n",
    "        df[feat + '_count'] = df[feat].map(df[feat].value_counts())\n",
    "    return(df)\n",
    "\n",
    "feature_list = ['regDate','creatDate','regDate_year','model','brand','regionCode','bodyType',\n",
    "                'fuelType','gearbox','notRepairedDamage']\n",
    "data = count_features(data, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/csdn/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 计算某品牌的销售统计量，同学们还可以计算其他特征的统计量\n",
    "# 这里要以 train 的数据计算统计量\n",
    "Train_gb = train.groupby(\"brand\")\n",
    "all_info = {}\n",
    "for kind, kind_data in Train_gb:\n",
    "    info = {}\n",
    "    kind_data = kind_data[kind_data['price'] > 0]\n",
    "    info['brand_amount'] = len(kind_data)\n",
    "    info['brand_price_max'] = kind_data.price.max()\n",
    "    info['brand_price_median'] = kind_data.price.median()\n",
    "    info['brand_price_min'] = kind_data.price.min()\n",
    "    info['brand_price_sum'] = kind_data.price.sum()\n",
    "    info['brand_price_ptp'] = kind_data.price.ptp()\n",
    "    info['brand_price_std'] = kind_data.price.std()\n",
    "    info['brand_price_average'] = round(kind_data.price.sum() / (len(kind_data) + 1), 2)\n",
    "    all_info[kind] = info\n",
    "brand_fe = pd.DataFrame(all_info).T.reset_index().rename(columns={\"index\": \"brand\"})\n",
    "data = data.merge(brand_fe, how='left', on='brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/csdn/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 计算某品牌的销售统计量，同学们还可以计算其他特征的统计量\n",
    "# 这里要以 train 的数据计算统计量\n",
    "Train_gb = train.groupby(\"model\")\n",
    "all_info = {}\n",
    "for kind, kind_data in Train_gb:\n",
    "    info = {}\n",
    "    kind_data = kind_data[kind_data['price'] > 0]\n",
    "    info['model_amount'] = len(kind_data)\n",
    "    info['model_price_max'] = kind_data.price.max()\n",
    "    info['model_price_median'] = kind_data.price.median()\n",
    "    info['model_price_min'] = kind_data.price.min()\n",
    "    info['model_price_sum'] = kind_data.price.sum()\n",
    "    info['model_price_ptp'] = kind_data.price.ptp()\n",
    "    info['model_price_std'] = kind_data.price.std()\n",
    "    info['model_price_average'] = round(kind_data.price.sum() / (len(kind_data) + 1), 2)\n",
    "    all_info[kind] = info\n",
    "model_fe = pd.DataFrame(all_info).T.reset_index().rename(columns={\"index\": \"model\"})\n",
    "data = data.merge(model_fe, how='left', on='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建统计量函数\n",
    "def Group_Statistic(train,data,feature,Target):\n",
    "    Train_gb = train.groupby(feature)\n",
    "    all_info = {}\n",
    "    for kind, kind_data in Train_gb:\n",
    "        info = {}\n",
    "        kind_data = kind_data[kind_data[Target] > 0]\n",
    "#         info[feature + '_amount'] = len(kind_data)\n",
    "        info[feature + '_' + Target + '_max'] = kind_data[Target].max()\n",
    "        info[feature + '_' + Target + '_median'] = kind_data[Target].median()\n",
    "        info[feature + '_' + Target + '_min'] = kind_data[Target].min()\n",
    "        info[feature + '_' + Target + '_sum'] = kind_data[Target].sum()\n",
    "        info[feature + '_' + Target + '_std'] = kind_data[Target].std()\n",
    "        info[feature + '_' + Target + '_average'] = round(kind_data[Target].sum() / (len(kind_data) + 1), 2)\n",
    "        all_info[kind] = info\n",
    "    new_df = pd.DataFrame(all_info).T.reset_index().rename(columns={'index': feature})\n",
    "    new_df[feature] = new_df[feature].astype(type(data[feature][0]))\n",
    "    return data.merge(new_df, how='left', on=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['used_time_bin'] = pd.cut(data['used_time_month'], bins=30, labels=False, include_lowest=True)\n",
    "train['used_time_month'] = data.iloc[:len(train),:]['used_time_month']\n",
    "data = Group_Statistic(train,data,'brand','used_time_month')\n",
    "data = Group_Statistic(train,data,'model','used_time_month')\n",
    "# data = Group_Statistic(train,data,'bodyType', 'price')\n",
    "\n",
    "# 构建 model + brand 和 price 的统计量\n",
    "data['brand'] = data['brand'].map(lambda x:str(x))\n",
    "data['model'] = data['model'].map(lambda x:str(x))\n",
    "data['model_brand'] = data['model'].str.cat(data['brand'], sep = '_')\n",
    "train['model_brand'] = data.iloc[:len(train),:]['model_brand']\n",
    "\n",
    "data = Group_Statistic(train,data,'model_brand','price')\n",
    "data = data.drop(['model_brand'], axis=1)\n",
    "\n",
    "# data['brand'] = data['brand'].astype(np.int64)\n",
    "# data['model'] = data['model'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 用数值特征对类别特征做统计刻画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.17it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.37it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.69it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.38s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.00s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.23it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.48it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.91it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.46s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:06<00:19,  6.57s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:11<00:12,  6.18s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:17<00:05,  5.92s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:22<00:00,  5.60s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:28<00:00,  9.34s/it]\n"
     ]
    }
   ],
   "source": [
    "#定义交叉特征统计\n",
    "def cross_cat_num(df,cat_col,num_col):\n",
    "    for f1 in tqdm(cat_col):\n",
    "        g = df.groupby(f1, as_index=False)\n",
    "        for f2 in tqdm(num_col):\n",
    "            feat = g[f2].agg({\n",
    "                '{}_{}_max'.format(f1, f2): 'max', '{}_{}_min'.format(f1, f2): 'min',\n",
    "                '{}_{}_median'.format(f1, f2): 'median', '{}_{}_mean'.format(f1, f2): 'mean',\n",
    "                '{}_{}_std'.format(f1, f2): 'std', '{}_{}_mad'.format(f1, f2): 'mad',\n",
    "            })\n",
    "            df = df.merge(feat, on=f1, how='left')\n",
    "    return(df)\n",
    "\n",
    "# 用数值特征对类别特征做统计刻画，挑了几个跟price相关性最高的匿名特征\n",
    "cross_cat = ['model', 'brand', 'regionCode']\n",
    "cross_num = ['v_0', 'v_3', 'v_8', 'v_12']\n",
    "data = cross_cat_num(data,cross_cat,cross_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price    50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = data.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_std = ['model_price_std','model_v_0_std','model_v_3_std','model_v_8_std', 'model_v_12_std', 'regionCode_v_0_std', 'regionCode_v_3_std',\n",
    "                'regionCode_v_8_std','regionCode_v_12_std','model_brand_price_std','model_used_time_month_std']\n",
    "\n",
    "for feat in features_std:\n",
    "    data[feat].fillna(data[feat].min(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 类别特征的二阶交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:33<00:00, 11.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "for f_pair in tqdm([['model', 'brand'],['model', 'regionCode'],['brand', 'regionCode']]):\n",
    "   \n",
    "    # 共现次数\n",
    "    data['_'.join(f_pair) + '_count'] = data.groupby(f_pair)['SaleID'].transform('count')\n",
    "                    \n",
    "    # nunique、熵\n",
    "    data = data.merge(data.groupby(f_pair[0], as_index=False)[f_pair[1]].agg({\n",
    "        '{}_{}_nunique'.format(f_pair[0], f_pair[1]): 'nunique',\n",
    "        '{}_{}_ent'.format(f_pair[0], f_pair[1]): lambda x: entropy(x.value_counts() / x.shape[0])}), on=f_pair[0], how='left')\n",
    "    \n",
    "    data = data.merge(data.groupby(f_pair[1], as_index=False)[f_pair[0]].agg({\n",
    "        '{}_{}_nunique'.format(f_pair[1], f_pair[0]): 'nunique',\n",
    "        '{}_{}_ent'.format(f_pair[1], f_pair[0]): lambda x: entropy(x.value_counts() / x.shape[0])}), on=f_pair[1], how='left')\n",
    "\n",
    "    # 比例偏好\n",
    "    data['{}_in_{}_prop'.format(f_pair[0], f_pair[1])] = data['_'.join(f_pair) + '_count'] / data[f_pair[1] + '_count']\n",
    "    data['{}_in_{}_prop'.format(f_pair[1], f_pair[0])] = data['_'.join(f_pair) + '_count'] / data[f_pair[0] + '_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 后验概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) bodyType, fuelType, gearBox在品牌brand中的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bodyType, fuelType, gearBox字段做独热编码, 并计算相关概率\n",
    "dummy_feat = ['bodyType', 'fuelType', 'gearbox']\n",
    "concat = data.drop(['train','price'], axis=1)\n",
    "\n",
    "for feat in dummy_feat:\n",
    "    dummies = pd.get_dummies(concat[feat])\n",
    "    dummies.columns = ['brand_%s_'%feat + '%s'%col for col in dummies.columns]\n",
    "    dummies['brand'] = concat['brand'].values\n",
    "    dummies = dummies.groupby('brand').mean()\n",
    "    dummies.reset_index()\n",
    "    data = data.merge(dummies, on='brand', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) bodyType, fuelType, gearBox, model在地区regionCode中的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bodyType, fuelType, gearBox, model字段做独热编码, 并计算相关概率\n",
    "dummy_feat = ['bodyType', 'fuelType', 'gearbox','model']\n",
    "concat = data.drop(['train','price'], axis=1)\n",
    "\n",
    "for feat in dummy_feat:\n",
    "    dummies = pd.get_dummies(concat[feat])\n",
    "    dummies.columns = ['regionCode_%s_'%feat + '%s'%col for col in dummies.columns]\n",
    "    dummies['regionCode'] = concat['regionCode'].values\n",
    "    dummies = dummies.groupby('regionCode').mean()\n",
    "    dummies.reset_index()\n",
    "    data = data.merge(dummies, on='regionCode', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 保存处理好的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SaleID', 'bodyType', 'brand', 'creatDate', 'fuelType', 'gearbox',\n",
      "       'kilometer', 'model', 'name', 'notRepairedDamage',\n",
      "       ...\n",
      "       'regionCode_model_ent', 'model_in_regionCode_prop',\n",
      "       'regionCode_in_model_prop', 'brand_regionCode_count',\n",
      "       'brand_regionCode_nunique', 'brand_regionCode_ent',\n",
      "       'regionCode_brand_nunique', 'regionCode_brand_ent',\n",
      "       'brand_in_regionCode_prop', 'regionCode_in_brand_prop'],\n",
      "      dtype='object', length=184)\n",
      "(150000, 180)\n",
      "(50000, 180)\n"
     ]
    }
   ],
   "source": [
    "## 选择特征列\n",
    "numerical_cols = data.columns\n",
    "print(numerical_cols)\n",
    "\n",
    "cat_fea = ['offerType','seller']\n",
    "feature_cols = [col for col in numerical_cols if col not in cat_fea]\n",
    "feature_cols = [col for col in feature_cols if col not in ['price']]\n",
    "\n",
    "## 提前特征列，标签列构造训练样本和测试样本\n",
    "X_data = data.iloc[:len(train),:][feature_cols]\n",
    "Y_data = train['price']\n",
    "X_test  = data.iloc[len(train):,:][feature_cols]\n",
    "\n",
    "#删除已经编码的特征\n",
    "# drop_list = one_hot_list + feature_list\n",
    "drop_list = ['creatDate']\n",
    "\n",
    "X_data = X_data.drop(drop_list,axis=1)\n",
    "X_test = X_test.drop(drop_list,axis=1)\n",
    "\n",
    "print(X_data.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_data, Y_data], axis=1, ignore_index=False)\n",
    "train.to_csv('../data/training/train_data_180.csv', index=False)\n",
    "X_test.to_csv('../data/training/test_data_180.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
