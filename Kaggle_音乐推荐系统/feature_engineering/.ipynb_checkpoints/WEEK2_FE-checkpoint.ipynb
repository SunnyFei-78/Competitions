{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "8e0b1726-10bb-4690-9e1d-fd44218a91a7"
   },
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "8e0b1726-10bb-4690-9e1d-fd44218a91a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 读取原始数据\n",
    "train = pd.read_csv('../source/train.csv')\n",
    "test = pd.read_csv('../source/test.csv')\n",
    "members = pd.read_csv('../source/members.csv')\n",
    "songs = pd.read_csv('../source/songs.csv')\n",
    "song_extra = pd.read_csv('../source/song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "9cd4af2a-a24a-47ba-9667-abf1fc795df8"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "e97a126d-49ce-40a2-8a11-3796f12b1351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7377418, 6, 2556790, 6, 2296320, 7, 2295971, 3, 34403, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape + test.shape + songs.shape + song_extra.shape + members.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "2073082f-1d25-40bc-868b-a7458c977ada"
   },
   "outputs": [],
   "source": [
    "# 用训练集的后百分之二十数据作为验证集\n",
    "test = train[math.ceil(train.shape[0] * 0.8):]\n",
    "train = train[0:math.ceil(train.shape[0] * 0.8)]\n",
    "test.to_csv('../training/validation.csv', index = False)\n",
    "train.to_csv('../training/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "414d8d3c-759a-483e-886b-914211316d36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5901935, 6, 1475483, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape + test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "8e0b1726-10bb-4690-9e1d-fd44218a91a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('../training/train.csv')\n",
    "test = pd.read_csv('../training/validation.csv')\n",
    "members = pd.read_csv('../source/members.csv')\n",
    "songs = pd.read_csv('../source/songs.csv')\n",
    "song_extra = pd.read_csv('../source/song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellType": "code",
    "uuid": "72f76688-abbe-4804-986e-c409d07cd0a1"
   },
   "outputs": [],
   "source": [
    "## 删除songs表中没有出现在训练和测试数据中的歌曲, 剩下419781首songs信息（原数据有2296320首歌曲）\n",
    "song_id_set = set(train['song_id'].append(test['song_id']))\n",
    "songs['appeared'] = songs['song_id'].apply(lambda x: True if x in song_id_set else False)\n",
    "songs = songs[songs.appeared]\n",
    "songs.drop('appeared', axis=1, inplace=True)\n",
    "\n",
    "## 删除song_extra表中没有出现在训练和测试数据中的歌曲信息, 剩下419661条songs额外信息（原数据有2295971条信息）\n",
    "song_extra['appeared'] = song_extra['song_id'].apply(lambda x: True if x in song_id_set else False)\n",
    "song_extra = song_extra[song_extra.appeared]\n",
    "song_extra.drop('appeared', axis=1, inplace=True)\n",
    "\n",
    "## members表中的用户都在训练和测试集中出现，不需要删除\n",
    "msno_set = set(train['msno'].append(test['msno']))\n",
    "members['appeared'] = members['msno'].apply(lambda x: True if x in msno_set else False)\n",
    "members = members[members.appeared]\n",
    "members.drop('appeared', axis=1, inplace=True)\n",
    "\n",
    "# 把年龄异常的数据统一归为一类，并作为一个新特征加入\n",
    "members['bd'] = members['bd'].apply(lambda x: np.nan if x<=0 or x >=80 else x)\n",
    "members['bd_missing'] = (members['bd'].isnull()) * 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填补songs表中缺失值\n",
    "songs['genre_ids'].fillna('0', inplace=True)\n",
    "songs['artist_name'].fillna('no_artist_name', inplace=True)\n",
    "songs['composer'].fillna('no_composer', inplace=True)\n",
    "songs['lyricist'].fillna('no_lyricist', inplace=True)\n",
    "\n",
    "# 获取language缺失的唯一一条记录的演唱者，找到演唱者其他歌曲的语言，来填充这个缺失值\n",
    "songs_temp = songs.loc[songs['language'].isnull()]\n",
    "language_value = (songs.loc[songs['artist_name'] == (songs_temp['artist_name'].values)[0]]['language'][0:1].values)[0]\n",
    "songs['language'].fillna(language_value, inplace=True)\n",
    "\n",
    "# 填补members表中缺失值\n",
    "members['bd'].fillna(members['bd'].median(), inplace=True)\n",
    "members['gender'].fillna('Other', inplace=True)\n",
    "\n",
    "# 填补训练集中缺失值\n",
    "train['source_system_tab'].fillna(train['source_system_tab'].mode()[0], inplace=True)\n",
    "train['source_screen_name'].fillna(train['source_screen_name'].mode()[0], inplace=True)\n",
    "train['source_type'].fillna(train['source_type'].mode()[0], inplace=True)\n",
    "\n",
    "# 填补验证集中缺失值\n",
    "test['source_system_tab'].fillna(test['source_system_tab'].mode()[0], inplace=True)\n",
    "test['source_screen_name'].fillna(test['source_screen_name'].mode()[0], inplace=True)\n",
    "test['source_type'].fillna(test['source_type'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "markdown",
    "uuid": "18bddd4b-2384-4c3f-ab93-f3026ca137cd"
   },
   "source": [
    "## 4. LabelEncodor编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "6199be39-5075-4f88-bdf1-b3ad7cdc278d"
   },
   "outputs": [],
   "source": [
    "## 对所有的msno做labelEncoder编码\n",
    "msno_encoder = LabelEncoder()\n",
    "msno_encoder.fit(members['msno'].values)\n",
    "members['msno'] = msno_encoder.transform(members['msno'])\n",
    "train['msno'] = msno_encoder.transform(train['msno'])\n",
    "test['msno'] = msno_encoder.transform(test['msno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "23460424-fe6a-4dec-9371-7e8547bf362b"
   },
   "outputs": [],
   "source": [
    "# 对所有的song_id做labelEncoder编码\n",
    "song_id_encoder = LabelEncoder()\n",
    "song_id_encoder.fit(train['song_id'].append(test['song_id']))\n",
    "songs['song_id'] = song_id_encoder.transform(songs['song_id'])\n",
    "song_extra['song_id'] = song_id_encoder.transform(song_extra['song_id'])\n",
    "train['song_id'] = song_id_encoder.transform(train['song_id'])\n",
    "test['song_id'] = song_id_encoder.transform(test['song_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "d59cb2b8-ed93-4a68-9cce-585ade58bee3"
   },
   "outputs": [],
   "source": [
    "# 对train和test中其他类别型变量做labelEncoder编码\n",
    "columns = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "for column in columns:\n",
    "    column_encoder = LabelEncoder()\n",
    "    column_encoder.fit(train[column].append(test[column]))\n",
    "    train[column] = column_encoder.transform(train[column])\n",
    "    test[column] = column_encoder.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "f5860b16-83ee-44fb-baef-79ab662cde89"
   },
   "outputs": [],
   "source": [
    "# 对members中的city、gender、registered_via做labelEncoder编码\n",
    "columns = ['city', 'gender', 'registered_via']\n",
    "for column in columns:\n",
    "    column_encoder = LabelEncoder()\n",
    "    column_encoder.fit(members[column])\n",
    "    members[column] = column_encoder.transform(members[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 处理songs表中字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "uuid": "856f7bee-4c5f-4be3-ae28-732d522c30fe"
   },
   "outputs": [],
   "source": [
    "# 处理genre_ids, 分割成  first_genre_id\n",
    "#                      second_genre_id\n",
    "#                      third_genre_id\n",
    "# 统计一首歌出现的流派数目 genre_id_cnt\n",
    "\n",
    "genre_id = np.zeros((len(songs), 4))\n",
    "for i in range(len(songs)):\n",
    "    ids = str(songs['genre_ids'].values[i]).split('|')\n",
    "    if len(ids) > 2:\n",
    "        genre_id[i, 0] = int(ids[0])\n",
    "        genre_id[i, 1] = int(ids[1])\n",
    "        genre_id[i, 2] = int(ids[2])\n",
    "    elif len(ids) > 1:\n",
    "        genre_id[i, 0] = int(ids[0])\n",
    "        genre_id[i, 1] = int(ids[1])\n",
    "    elif len(ids) == 1:\n",
    "        genre_id[i, 0] = int(ids[0])\n",
    "    genre_id[i, 3] = len(ids)\n",
    "songs['first_genre_id'] = genre_id[:, 0]\n",
    "songs['second_genre_id'] = genre_id[:, 1]\n",
    "songs['third_genre_id'] = genre_id[:, 2]\n",
    "songs['genre_id_cnt'] = genre_id[:, 3]\n",
    "\n",
    "# 对提取的三个流派做labelEncoder\n",
    "genre_encoder = LabelEncoder()\n",
    "genre_encoder.fit((songs.first_genre_id.append(songs.second_genre_id)).append(songs.third_genre_id))\n",
    "songs['first_genre_id'] = genre_encoder.transform(songs['first_genre_id'])\n",
    "songs['second_genre_id'] = genre_encoder.transform(songs['second_genre_id'])\n",
    "songs['third_genre_id'] = genre_encoder.transform(songs['third_genre_id'])\n",
    "songs.drop('genre_ids', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "4c1f0ea3-6333-443e-a037-10449eb56133"
   },
   "outputs": [],
   "source": [
    "# 统计每首歌的歌手数目\n",
    "def artist_count(x):\n",
    "    return x.count('and') + x.count(',') + x.count(' feat') + x.count('&') + 1\n",
    "songs['artist_cnt'] = songs['artist_name'].apply(artist_count).astype(np.int64)\n",
    "\n",
    "def get_count(x):\n",
    "    try:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    except:\n",
    "        return 0\n",
    "# 统计每首歌的作词人数目\n",
    "songs['lyricist_cnt'] = songs['lyricist'].apply(get_count).astype(np.int64)\n",
    "# 统计每首歌的作曲人数目\n",
    "songs['composer_cnt'] = songs['composer'].apply(get_count).astype(np.int64)\n",
    "# 统计每首歌是独唱还是合唱\n",
    "songs['is_featured'] = songs['artist_name'].apply(lambda x: 1 if ' feat' in str(x) else 0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "aff1d39f-ea7b-4c71-83ab-c9e06c63db19"
   },
   "outputs": [],
   "source": [
    "# 歌曲的演唱者只保留第一个\n",
    "def get_first_artist(x):\n",
    "    if x.count('and') > 0:\n",
    "        x = x.split('and')[0]\n",
    "    if x.count(',') > 0:\n",
    "        x = x.split(',')[0]\n",
    "    if x.count(' feat') > 0:\n",
    "        x = x.split(' feat')[0]\n",
    "    if x.count('&') > 0:\n",
    "        x = x.split('&')[0]\n",
    "    return x.strip()\n",
    "songs['artist_name'] = songs['artist_name'].apply(get_first_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "uuid": "8b7cde8d-efa3-48e9-b7ce-4ed5061ef767"
   },
   "outputs": [],
   "source": [
    "# 歌曲的作词人和作曲人都只保留第一个\n",
    "def get_first_term(x):\n",
    "    try:\n",
    "        if x.count('|') > 0:\n",
    "            x = x.split('|')[0]\n",
    "        if x.count('/') > 0:\n",
    "            x = x.split('/')[0]\n",
    "        if x.count('\\\\') > 0:\n",
    "            x = x.split('\\\\')[0]\n",
    "        if x.count(';') > 0:\n",
    "            x = x.split(';')[0]\n",
    "        return x.strip()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "songs['lyricist'] = songs['lyricist'].apply(get_first_term)\n",
    "songs['composer'] = songs['composer'].apply(get_first_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "uuid": "94389062-5388-4be1-ae90-7e902cc06839"
   },
   "outputs": [],
   "source": [
    "# 对处理后的artist_name、composer、lyricist、language做LabelEncoder        \n",
    "columns = ['artist_name', 'lyricist', 'composer','language']\n",
    "for column in columns:\n",
    "    column_encoder = LabelEncoder()\n",
    "    column_encoder.fit(songs[column])\n",
    "    songs[column] = column_encoder.transform(songs[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "02e88489-7302-4795-afea-2b402d7ac025"
   },
   "outputs": [],
   "source": [
    "# 按演唱者分类，统计每个演唱者唱过几首歌\n",
    "artist_song_cnt = songs.groupby(by='artist_name').count()['song_id'].to_dict()\n",
    "songs['artist_song_cnt'] = songs['artist_name'].apply(lambda x: artist_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按作曲人分类，统计每个作曲人编曲数目\n",
    "composer_song_cnt = songs.groupby(by='composer').count()['song_id'].to_dict()\n",
    "songs['composer_song_cnt'] = songs['composer'].apply(lambda x: composer_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按作词人分类，统计每个作词人作词数目\n",
    "lyricist_song_cnt = songs.groupby(by='lyricist').count()['song_id'].to_dict()\n",
    "songs['lyricist_song_cnt'] = songs['lyricist'].apply(lambda x: lyricist_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按歌曲风格分类，统计每个流派包含多少首歌\n",
    "genre_song_cnt = songs.groupby(by='first_genre_id').count()['song_id'].to_dict()\n",
    "songs['genre_song_cnt'] = songs['first_genre_id'].apply(lambda x: genre_song_cnt[x] if not np.isnan(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过处理后的songs增加以下四个新特征：\n",
    "artist_song_cnt：  统计每个演唱者唱过几首歌\n",
    "\n",
    "composer_song_cnt：统计每个作曲人编曲数目\n",
    "\n",
    "lyricist_song_cnt：统计每个作词人作词数目\n",
    "\n",
    "genre_song_cnt：   统计每个风格包含多少首歌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 处理song_extra中字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 歌曲出版的国家码 -- cn\n",
    "# 歌曲出版者码    -- xxx\n",
    "# 歌曲录制年份    -- year \n",
    "data = train[['msno', 'song_id']].append(test[['msno', 'song_id']])\n",
    "songs = songs.merge(song_extra, on='song_id', how='left')\n",
    "\n",
    "isrc = songs['isrc']\n",
    "songs['cn'] = isrc.str.slice(0, 2)\n",
    "songs['xxx'] = isrc.str.slice(2, 5)\n",
    "songs['year'] = isrc.str.slice(5, 7).astype(float)\n",
    "# 歌曲录制的年份转换为4位\n",
    "songs['year'] = songs['year'].apply(lambda x: 2000+x if x < 18 else 1900+x)\n",
    "\n",
    "# 增加一个新特征，代表是否isrc缺失\n",
    "songs['isrc_missing'] = (songs['cn'].isnull()) * 1.0\n",
    "songs['cn'] = LabelEncoder().fit_transform(songs['cn'].fillna('None'))\n",
    "songs['xxx'] = LabelEncoder().fit_transform(songs['xxx'].fillna('None'))\n",
    "songs['year'].fillna(songs['year'].median(),inplace=True)\n",
    "\n",
    "# 按国家码分类，统计每个国家码的歌曲数目\n",
    "song_cn_cnt = songs.groupby(by='cn').count()['song_id'].to_dict()\n",
    "songs['cn_song_cnt'] = songs['cn'].apply(lambda x: song_cn_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "# 按出版码分类，统计每个出版者出版的歌曲数目\n",
    "song_xxx_cnt = songs.groupby(by='xxx').count()['song_id'].to_dict()\n",
    "songs['xxx_song_cnt'] = songs['xxx'].apply(lambda x: song_xxx_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "# 按歌曲年份分类，统计每个年份录制的歌曲数目\n",
    "song_year_cnt = songs.groupby(by='year').count()['song_id'].to_dict()\n",
    "songs['year_song_cnt'] = songs['year'].apply(lambda x: song_year_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "data = data.merge(songs, on='song_id', how='left')\n",
    "# 按国家码分类，统计每个国家码下有多少用户收听\n",
    "song_cn_cnt = data.groupby(by='cn').count()['msno'].to_dict()\n",
    "songs['cn_rec_cnt'] = songs['cn'].apply(lambda x: song_cn_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "# 按出版码分类，统计每个出版码下有多少用户收听\n",
    "song_xxx_cnt = data.groupby(by='xxx').count()['msno'].to_dict()\n",
    "songs['xxx_rec_cnt'] = songs['xxx'].apply(lambda x: song_xxx_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "# 按歌曲年份分类，统计每个年份下有多少用户收听\n",
    "song_year_cnt = data.groupby(by='year').count()['msno'].to_dict()\n",
    "songs['year_rec_cnt'] = songs['year'].apply(lambda x: song_year_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "features = ['cn_song_cnt', 'xxx_song_cnt', 'year_song_cnt', 'cn_rec_cnt', 'xxx_rec_cnt', 'year_rec_cnt']\n",
    "for feat in features:\n",
    "    songs[feat] = np.log1p(songs[feat])\n",
    "\n",
    "songs.drop(['name', 'isrc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "uuid": "16398e99-3a1c-4c53-ab7d-9f0b4fa80a43"
   },
   "outputs": [],
   "source": [
    "# 按歌曲id分类，统计每首歌被播放的用户数目\n",
    "song_rec_cnt = data.groupby(by='song_id').count()['msno'].to_dict()\n",
    "songs['song_rec_cnt'] = songs['song_id'].apply(lambda x: song_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按演唱者分类，统计每个演唱者被收听过的用户数目\n",
    "artist_rec_cnt = data.groupby(by='artist_name').count()['msno'].to_dict()\n",
    "songs['artist_rec_cnt'] = songs['artist_name'].apply(lambda x: artist_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按作曲人分类，统计每个作曲人被收听过的用户数目\n",
    "composer_rec_cnt = data.groupby(by='composer').count()['msno'].to_dict()\n",
    "songs['composer_rec_cnt'] = songs['composer'].apply(lambda x: composer_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按作词人分类，统计每个作词人被收听的用户数目\n",
    "lyricist_rec_cnt = data.groupby(by='lyricist').count()['msno'].to_dict()\n",
    "songs['lyricist_rec_cnt'] = songs['lyricist'].apply(lambda x: lyricist_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "# 按first_genre_id流派分类，统计每个风格被收听的用户数目\n",
    "genre_rec_cnt = data.groupby(by='first_genre_id').count()['msno'].to_dict()\n",
    "songs['genre_rec_cnt'] = songs['first_genre_id'].apply(lambda x: genre_rec_cnt[x] if not np.isnan(x) else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对以下特征做log变换\n",
    "features = ['song_length', 'song_rec_cnt', 'artist_song_cnt', 'composer_song_cnt', \\\n",
    "        'lyricist_song_cnt', 'genre_song_cnt', 'artist_rec_cnt', \\\n",
    "        'composer_rec_cnt', 'lyricist_rec_cnt', 'genre_rec_cnt']\n",
    "for feat in features:\n",
    "    songs[feat] = np.log1p(songs[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "uuid": "c38f6e8a-4e20-4d34-9d08-fd03461cc698"
   },
   "outputs": [],
   "source": [
    "# count：训练集里每首歌曲被听取的次数，即该歌曲在数据集中出现的总次数\n",
    "# mean：被重复听取的概率（sum(target=1)/count，即一歌曲被用户第二次播放/该歌曲在数据集中出现的总次数\n",
    "train_merge_songs = train[['msno', 'song_id','target']].append(test[['msno', 'song_id','target']]).merge(songs,on='song_id')\n",
    "song_mean_count = train_merge_songs[['song_id', 'target']].groupby(['song_id']).agg(['mean', 'count'])\n",
    "song_mean_count.reset_index(inplace=True)\n",
    "song_mean_count.columns = list(map(''.join, song_mean_count.columns.values))\n",
    "song_mean_count.columns = ['song_id', 'repeat_play_chance', 'plays']  #rename columns\n",
    "songs = songs.merge(song_mean_count, on='song_id',how='right') # merge song data with computed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 处理members中字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "uuid": "97ace6b9-5abf-4557-832a-61bffa4fad6d"
   },
   "outputs": [],
   "source": [
    "data = train[['msno', 'song_id']].append(test[['msno', 'song_id']])\n",
    "\n",
    "# 统计一个用户听过多少首歌(训练集+测试集)\n",
    "mem_rec_cnt = data.groupby(by='msno').count()['song_id'].to_dict()\n",
    "members['msno_rec_cnt'] = members['msno'].apply(lambda x: mem_rec_cnt[x])\n",
    "\n",
    "## log1p变换\n",
    "features = ['msno_rec_cnt']\n",
    "for feat in features:\n",
    "    members[feat] = np.log1p(members[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 到期时间减去注册时间，得到用户的会员时间，作为新特征加入members\n",
    "members['expiration_date'] = members['expiration_date'].astype(np.str)\n",
    "members['registration_init_time'] = members['registration_init_time'].astype(np.str)\n",
    "members['membership_days'] = pd.to_datetime(members['expiration_date']).subtract(pd.to_datetime(members['registration_init_time'])).dt.days.astype(int)\n",
    "\n",
    "# 将registration_init_time拆分成年、月、日，并作为新特征加入到menmbers中\n",
    "members['registration_year'] = pd.to_datetime(members['registration_init_time']).dt.year\n",
    "members['registration_month'] = pd.to_datetime(members['registration_init_time']).dt.month\n",
    "members['registration_day'] = pd.to_datetime(members['registration_init_time']).dt.day\n",
    "\n",
    "# 将expiration_date拆分成年、月、日，并作为新特征加入到members中\n",
    "members['expiration_year'] = pd.to_datetime(members['expiration_date']).dt.year\n",
    "members['expiration_month'] = pd.to_datetime(members['expiration_date']).dt.month\n",
    "members['expiration_day'] = pd.to_datetime(members['expiration_date']).dt.day\n",
    "\n",
    "members['registration_init_time'] = members['registration_init_time'].apply(lambda x: \\\n",
    "        time.mktime(time.strptime(str(x),'%Y%m%d')))\n",
    "members['expiration_date'] = members['expiration_date'].apply(lambda x: \\\n",
    "        time.mktime(time.strptime(str(x),'%Y%m%d')))\n",
    "members = members.drop(['registration_init_time','expiration_date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "uuid": "1870f191-3478-42d1-8d82-f50595902f0e"
   },
   "outputs": [],
   "source": [
    "# 对train和test中的相关source的三个字段做独热编码, 并计算相关概率\n",
    "dummy_feat = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "concat_train_test = train.drop('target', axis=1).append(test.drop('target', axis=1))\n",
    "\n",
    "for feat in dummy_feat:\n",
    "    dummies = pd.get_dummies(concat_train_test[feat])\n",
    "    dummies.columns = ['msno_%s_'%feat + '%s'%col for col in dummies.columns]\n",
    "    dummies['msno'] = concat_train_test['msno'].values\n",
    "    dummies = dummies.groupby('msno').mean()\n",
    "    dummies.reset_index()\n",
    "    members = members.merge(dummies, on='msno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存中间过程文件， 方便调试\n",
    "train.to_csv('../training/train_validation_r1.csv', index=False)\n",
    "test.to_csv('../training/test_validaton_r1.csv', index=False)\n",
    "members.to_csv('../training/members_validation_r1.csv', index=False)\n",
    "songs.to_csv('../training/songs_validation_r1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 增加后验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "uuid": "6439abe2-25f9-4087-8fd0-5dab173b2ab9"
   },
   "outputs": [],
   "source": [
    "# 把用户的所有特征合并到训练集和验证集中\n",
    "train_temp = train.merge(members, on='msno', how='left')\n",
    "test_temp = test.merge(members, on='msno', how='left')\n",
    "\n",
    "# 查找训练集和验证集中包含‘source_system_tab’字符的特征\n",
    "train_source_system_tab = train_temp[[col for col in train_temp.columns if 'source_system_tab' in col]]\n",
    "test_source_system_tab =  test_temp[[col for col in test_temp.columns if 'source_system_tab' in col]]\n",
    "\n",
    "# 查找训练集和验证集中包含‘source_screen_name’字符的特征\n",
    "train_source_screen_name = train_temp[[col for col in train_temp.columns if 'source_screen_name' in col]]\n",
    "test_source_screen_name =  test_temp[[col for col in test_temp.columns if 'source_screen_name' in col]]\n",
    "\n",
    "# 查找训练集和验证集中包含‘source_type’字符的特征\n",
    "train_source_type = train_temp[[col for col in train_temp.columns if 'source_type' in col]]\n",
    "test_source_type =  test_temp[[col for col in test_temp.columns if 'source_type' in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "uuid": "f39c1314-ff65-4871-ae55-9a3ef2054f6c"
   },
   "outputs": [],
   "source": [
    "train['msno_source_system_tab_prob'] = train_source_system_tab.apply(lambda x: \\\n",
    "                                       x['msno_source_system_tab_%d'%x['source_system_tab']], axis=1)\n",
    "test['msno_source_system_tab_prob'] = test_source_system_tab.apply(lambda x: \\\n",
    "                                      x['msno_source_system_tab_%d'%x['source_system_tab']], axis=1)\n",
    "\n",
    "train['msno_source_screen_name_prob'] = train_source_screen_name.apply(lambda x: \\\n",
    "        x['msno_source_screen_name_%d'%x['source_screen_name']], axis=1)\n",
    "test['msno_source_screen_name_prob'] = test_source_screen_name.apply(lambda x: \\\n",
    "        x['msno_source_screen_name_%d'%x['source_screen_name']], axis=1)\n",
    "                                                                       \n",
    "train['msno_source_type_prob'] = train_source_type.apply(lambda x: \\\n",
    "        x['msno_source_type_%d'%x['source_type']], axis=1)\n",
    "test['msno_source_type_prob'] = test_source_type.apply(lambda x: \\\n",
    "        x['msno_source_type_%d'%x['source_type']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                            0\n",
       "song_id                         0\n",
       "source_system_tab               0\n",
       "source_screen_name              0\n",
       "source_type                     0\n",
       "target                          0\n",
       "msno_source_system_tab_prob     0\n",
       "msno_source_screen_name_prob    0\n",
       "msno_source_type_prob           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存包含后验概率的文件\n",
    "train.to_csv('../training/train_validation_prod.csv', index=False)\n",
    "test.to_csv('../training/test_validation_prob.csv', index=False)\n",
    "members.to_csv('../training/members_validation_prob.csv', index=False)\n",
    "songs.to_csv('../training/songs_validation_prob.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 用户-歌曲关系矩阵分解，用户-歌手关系矩阵分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "uuid": "8e0b1726-10bb-4690-9e1d-fd44218a91a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('../training/train_validation_prod.csv')\n",
    "test = pd.read_csv('../training/test_validation_prob.csv')\n",
    "members = pd.read_csv('../training/members_validation_prob.csv')\n",
    "songs = pd.read_csv('../training/songs_validation_prob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7377418\n"
     ]
    }
   ],
   "source": [
    "concat = train[['msno', 'song_id']].append(test[['msno', 'song_id']])\n",
    "member_cnt = concat['msno'].max() + 1\n",
    "song_cnt = concat['song_id'].max() + 1\n",
    "artist_cnt = int(songs['artist_name'].max() + 1)\n",
    "print(len(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[929.19644441 348.80981297 309.40275499 252.8020833  235.66103789\n",
      " 184.89734987 178.8854274  163.36788383 158.45152867 151.20234554\n",
      " 147.54990949 146.69235095 141.14892669 132.07849752 129.90593115\n",
      " 125.32091035 122.28441182 119.65531332 117.63870037 115.73739365\n",
      " 113.58651385 112.08390834 111.2969255  109.59026882 108.62116088\n",
      " 106.05728495 105.57023407 102.20677814 101.28490626 100.46536012\n",
      "  97.84094794  96.92911592  96.04246875  95.87283229  93.84138743\n",
      "  92.73973012  91.85405027  90.3989575   89.84799528  89.29548723\n",
      "  88.31527645  88.11258867  86.453424    86.01874769  84.99338776\n",
      "  84.59675956  83.97524489  83.40244589]\n",
      "7377304\n",
      "[1231.90585798  405.63937345  303.7062179   278.05664389  243.94539539\n",
      "  214.25753678  175.36567621  172.69229575  157.80083028  153.16554079\n",
      "  149.3448921   146.934055    138.7035043   135.44997276  132.95733285\n",
      "  126.14460143]\n"
     ]
    }
   ],
   "source": [
    "# 设计用户-歌曲关系矩阵，并做SVD分解成三个矩阵\n",
    "n_component = 48\n",
    "\n",
    "data = np.ones(len(concat))\n",
    "msno = concat['msno'].values\n",
    "song_id = concat['song_id'].values\n",
    "\n",
    "rating = sparse.coo_matrix((data, (msno, song_id)))\n",
    "rating = (rating > 0) * 1.0\n",
    "\n",
    "[u, s, vt] = svds(rating, k=n_component)\n",
    "print(s[::-1])\n",
    "s_song = np.diag(s[::-1])\n",
    "\n",
    "# 保留跟用户相关的48维特征，存入members表中\n",
    "members_topics = pd.DataFrame(u[:, ::-1])\n",
    "members_topics.columns = ['member_component_%d'%i for i in range(n_component)]\n",
    "members_topics['msno'] = range(member_cnt)\n",
    "members = members.merge(members_topics, on='msno', how='right')\n",
    "\n",
    "# 保留跟歌曲相关的48维特征，存入songs表中\n",
    "song_topics = pd.DataFrame(vt.transpose()[:, ::-1])\n",
    "song_topics.columns = ['song_component_%d'%i for i in range(n_component)]\n",
    "song_topics['song_id'] = range(song_cnt)\n",
    "songs = songs.merge(song_topics, on='song_id', how='right')\n",
    "\n",
    "# 设计用户-歌曲关系矩阵，并做SVD分解成三个矩阵 \n",
    "n_component = 16\n",
    "\n",
    "concat = concat.merge(songs[['song_id', 'artist_name']], on='song_id', how='left')\n",
    "concat = concat[concat['artist_name'] >= 0]\n",
    "msno = concat['msno'].values\n",
    "artist = concat['artist_name'].values.astype(int)\n",
    "\n",
    "print(len(concat))\n",
    "data = np.ones(len(concat))\n",
    "rating_tmp = sparse.coo_matrix((data, (msno, artist)))\n",
    "\n",
    "rating = np.log1p(rating_tmp) * 0.3 + (rating_tmp > 0) * 1.0\n",
    "\n",
    "[u, s, vt] = svds(rating, k=n_component)\n",
    "print(s[::-1])\n",
    "s_artist = np.diag(s[::-1])\n",
    "\n",
    "# 保留跟用户相关的16维特征，存入members表中\n",
    "members_topics = pd.DataFrame(u[:, ::-1])\n",
    "members_topics.columns = ['member_artist_component_%d'%i for i in range(n_component)]\n",
    "members_topics['msno'] = range(member_cnt)\n",
    "members = members.merge(members_topics, on='msno', how='left')\n",
    "\n",
    "# 保留跟artist name相关的16维特征，存入songs表中\n",
    "artist_topics = pd.DataFrame(vt.transpose()[:, ::-1])\n",
    "artist_topics.columns = ['artist_component_%d'%i for i in range(n_component)]\n",
    "artist_topics['artist_name'] = range(artist_cnt)\n",
    "songs = songs.merge(artist_topics, on='artist_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加新特征\n",
    "members = members.sort_values(by='msno')\n",
    "songs = songs.sort_values(by='song_id')\n",
    "\n",
    "mem_cols = ['member_component_%d'%i for i in range(48)]\n",
    "song_cols = ['song_component_%d'%i for i in range(48)]\n",
    "\n",
    "member_embeddings = members[mem_cols].values\n",
    "song_embeddings = songs[song_cols].values\n",
    "\n",
    "mem_cols = ['member_artist_component_%d'%i for i in range(16)]\n",
    "song_cols = ['artist_component_%d'%i for i in range(16)]\n",
    "\n",
    "member_artist_embeddings = members[mem_cols].values\n",
    "song_artist_embeddings = songs[song_cols].values\n",
    "\n",
    "train_dot = np.zeros((len(train), 2))\n",
    "test_dot = np.zeros((len(test), 2))\n",
    "\n",
    "for i in range(len(train)):\n",
    "    msno_idx = train['msno'].values[i]\n",
    "    song_idx = train['song_id'].values[i]\n",
    "    \n",
    "    train_dot[i, 0] = np.dot(member_embeddings[msno_idx], np.dot(s_song, song_embeddings[song_idx]))\n",
    "    train_dot[i, 1] = np.dot(member_artist_embeddings[msno_idx], np.dot(s_artist, song_artist_embeddings[song_idx]))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    msno_idx = test['msno'].values[i]\n",
    "    song_idx = test['song_id'].values[i]\n",
    "    \n",
    "    test_dot[i, 0] = np.dot(member_embeddings[msno_idx], np.dot(s_song, song_embeddings[song_idx]))\n",
    "    test_dot[i, 1] = np.dot(member_artist_embeddings[msno_idx], np.dot(s_artist, song_artist_embeddings[song_idx]))\n",
    "\n",
    "train['song_embeddings_dot'] = train_dot[:, 0]\n",
    "train['artist_embeddings_dot'] = train_dot[:, 1]\n",
    "\n",
    "test['song_embeddings_dot'] = test_dot[:, 0]\n",
    "test['artist_embeddings_dot'] = test_dot[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存SVD结果的文件\n",
    "train.to_csv('../training/train_validation_svd.csv', index=False)\n",
    "test.to_csv('../training/test_validation_svd.csv', index=False)\n",
    "members.to_csv('../training/members_validation_svd.csv', index=False)\n",
    "songs.to_csv('../training/songs_validation_svd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 整合各表，保存做完特征工程的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../training/train_validation_svd.csv')\n",
    "test = pd.read_csv('../training/test_validation_svd.csv')\n",
    "members = pd.read_csv('../training/members_validation_svd.csv')\n",
    "songs = pd.read_csv('../training/songs_validation_svd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据集\n",
    "train.to_csv('../training/train_final.csv', index=False, float_format='%.6f')\n",
    "test.to_csv('../training/test_final.csv', index=False, float_format='%.6f')\n",
    "members.to_csv('../training/members_gbdt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['composer', 'lyricist', 'language', 'first_genre_id', 'second_genre_id', 'third_genre_id']\n",
    "for col in columns:\n",
    "    songs[col].fillna(0, inplace=True)\n",
    "    songs[col] = songs[col].astype(int)\n",
    "songs['artist_name'].fillna((songs['artist_name'].max())+1, inplace=True)\n",
    "songs['artist_name'] = songs['artist_name'].astype(int)\n",
    "songs['isrc_missing'].fillna(0, inplace=True)\n",
    "songs['isrc_missing'] = songs['isrc_missing'].astype(int)\n",
    "songs.to_csv('../training/songs_gbdt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs['song_id_missing'] = np.isnan(songs['song_length'].values) * 1\n",
    "\n",
    "columns = ['song_length', 'genre_id_cnt', 'artist_cnt', 'lyricist_cnt', 'composer_cnt', 'is_featured',\\\n",
    "           'artist_song_cnt', 'composer_song_cnt', 'lyricist_song_cnt', 'genre_song_cnt', 'song_rec_cnt', \\\n",
    "           'artist_rec_cnt', 'composer_rec_cnt', 'lyricist_rec_cnt', 'genre_rec_cnt', 'cn', 'xxx', 'year', \\\n",
    "           'cn_song_cnt', 'xxx_song_cnt', 'year_song_cnt', 'cn_rec_cnt', 'xxx_rec_cnt', 'year_rec_cnt', \\\n",
    "           'repeat_play_chance','plays'] + ['artist_component_%d'%i for i in range(16)]\n",
    "for col in columns:\n",
    "    songs[col].fillna(np.nanmean(songs[col]), inplace=True)\n",
    "\n",
    "songs.to_csv('../training/songs_validation_nn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
